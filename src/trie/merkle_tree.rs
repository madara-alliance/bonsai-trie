#[cfg(not(feature = "std"))]
use alloc::{format, string::ToString, vec, vec::Vec};
use bitvec::{
    prelude::{BitSlice, BitVec, Msb0},
    view::BitView,
};
use core::iter::once;
use core::marker::PhantomData;
use core::mem;
use derive_more::Constructor;
#[cfg(not(feature = "std"))]
use hashbrown::HashMap;
use parity_scale_codec::{Decode, Encode};
#[cfg(feature = "std")]
use rayon::prelude::*;
use starknet_types_core::{felt::Felt, hash::StarkHash};
#[cfg(feature = "std")]
use std::collections::HashMap;

use crate::{error::BonsaiStorageError, id::Id, BonsaiDatabase, KeyValueDB};

use super::{
    merkle_node::{BinaryNode, Direction, EdgeNode, Node, NodeHandle, NodeId},
    path::Path,
    trie_db::TrieKeyType,
    TrieKey,
};

#[cfg(test)]
use log::trace;

#[derive(Debug, PartialEq, Eq)]
pub enum Membership {
    Member,
    NonMember,
}

/// Wrapper type for a [HashMap<NodeId, Node>] object. (It's not really a wrapper it's a
/// copy of the type but we implement the necessary traits.)
#[derive(Clone, Debug, PartialEq, Eq, Default, Constructor)]
pub struct NodesMapping(HashMap<NodeId, Node>);

/// A node used in proof generated by the trie.
///
/// See pathfinders merkle-tree crate for more information.
#[derive(Debug, Clone, PartialEq)]
pub enum ProofNode {
    Binary { left: Felt, right: Felt },
    Edge { child: Felt, path: Path },
}

impl ProofNode {
    pub fn hash<H: StarkHash>(&self) -> Felt {
        match self {
            ProofNode::Binary { left, right } => H::hash(left, right),
            ProofNode::Edge { child, path } => {
                let mut bytes = [0u8; 32];
                bytes.view_bits_mut::<Msb0>()[256 - path.0.len()..].copy_from_bitslice(&path.0);
                // SAFETY: path len is <= 251
                let path_hash = Felt::from_bytes_be(&bytes);

                let length = Felt::from(path.0.len() as u8);
                H::hash(child, &path_hash) + length
            }
        }
    }
}

pub(crate) struct MerkleTrees<H: StarkHash + Send + Sync, DB: BonsaiDatabase, CommitID: Id> {
    pub db: KeyValueDB<DB, CommitID>,
    pub trees: HashMap<Vec<u8>, MerkleTree<H>>,
}

#[cfg(feature = "bench")]
impl<H: StarkHash + Send + Sync, DB: BonsaiDatabase + Clone, CommitID: Id> Clone
    for MerkleTrees<H, DB, CommitID>
{
    fn clone(&self) -> Self {
        Self {
            db: self.db.clone(),
            trees: self.trees.clone(),
        }
    }
}

impl<H: StarkHash + Send + Sync, DB: BonsaiDatabase, CommitID: Id> MerkleTrees<H, DB, CommitID> {
    pub(crate) fn new(db: KeyValueDB<DB, CommitID>) -> Self {
        Self {
            db,
            trees: HashMap::new(),
        }
    }

    pub(crate) fn init_tree(
        &mut self,
        identifier: &[u8],
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let tree = MerkleTree::new(&mut self.db, identifier.to_vec())?;
        self.trees.insert(identifier.to_vec(), tree);
        Ok(())
    }

    pub(crate) fn set(
        &mut self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
        value: Felt,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get_mut(identifier);
        if let Some(tree) = tree {
            tree.set(&mut self.db, key, value)
        } else {
            let mut tree = MerkleTree::new(&mut self.db, identifier.to_vec())?;
            tree.set(&mut self.db, key, value)?;
            self.trees.insert(identifier.to_vec(), tree);
            Ok(())
        }
    }

    pub(crate) fn get(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.get(&self.db, key)
        } else {
            Ok(None)
        }
    }

    pub(crate) fn contains(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<bool, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.contains(&self.db, key)
        } else {
            Ok(false)
        }
    }

    pub(crate) fn db_mut(&mut self) -> &mut KeyValueDB<DB, CommitID> {
        &mut self.db
    }

    pub(crate) fn reset_to_last_commit(
        &mut self,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        for tree in self.trees.values_mut() {
            tree.reset_to_last_commit(&mut self.db)?;
        }
        Ok(())
    }

    pub(crate) fn db_ref(&self) -> &KeyValueDB<DB, CommitID> {
        &self.db
    }

    pub(crate) fn root_hash(
        &self,
        identifier: &[u8],
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            Ok(tree.root_hash())
        } else {
            Err(BonsaiStorageError::Trie("Tree not found".to_string()))
        }
    }

    pub(crate) fn get_keys(
        &self,
        identifier: &[u8],
    ) -> Result<Vec<Vec<u8>>, BonsaiStorageError<DB::DatabaseError>> {
        self.db
            .db
            .get_by_prefix(&crate::DatabaseKey::Flat(identifier))
            .map(|key_value_pairs| {
                // Remove the identifier from the key
                key_value_pairs
                    .into_iter()
                    // FIXME: this does not filter out keys values correctly for `HashMapDb` due
                    // to branches and leafs not being differenciated
                    .filter_map(|(key, _value)| {
                        if key.len() > identifier.len() {
                            Some(key[identifier.len() + 1..].to_vec())
                        } else {
                            None
                        }
                    })
                    .collect()
            })
            .map_err(|e| e.into())
    }

    #[allow(clippy::type_complexity)]
    pub(crate) fn get_key_value_pairs(
        &self,
        identifier: &[u8],
    ) -> Result<Vec<(Vec<u8>, Vec<u8>)>, BonsaiStorageError<DB::DatabaseError>> {
        self.db
            .db
            .get_by_prefix(&crate::DatabaseKey::Flat(identifier))
            .map(|key_value_pairs| {
                key_value_pairs
                    .into_iter()
                    // FIXME: this does not filter out keys values correctly for `HashMapDb` due
                    // to branches and leafs not being differenciated
                    .filter_map(|(key, value)| {
                        if key.len() > identifier.len() {
                            Some((key[identifier.len() + 1..].to_vec(), value))
                        } else {
                            None
                        }
                    })
                    .collect()
            })
            .map_err(|e| e.into())
    }

    pub(crate) fn commit(&mut self) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        #[cfg(not(feature = "std"))]
        let db_changes = self
            .trees
            .iter_mut()
            .map(|(_, tree)| tree.get_updates::<DB>())
            .collect::<Result<Vec<_>, BonsaiStorageError<DB::DatabaseError>>>()?;
        #[cfg(feature = "std")]
        let db_changes = self
            .trees
            .par_iter_mut()
            .map(|(_, tree)| tree.get_updates::<DB>())
            .collect::<Result<Vec<_>, BonsaiStorageError<DB::DatabaseError>>>()?;

        let mut batch = self.db.create_batch();
        for changes in db_changes {
            for (key, value) in changes {
                match value {
                    InsertOrRemove::Insert(value) => {
                        self.db.insert(&key, &value, Some(&mut batch))?;
                    }
                    InsertOrRemove::Remove => {
                        self.db.remove(&key, Some(&mut batch))?;
                    }
                }
            }
        }
        self.db.write_batch(batch)?;
        Ok(())
    }

    pub(crate) fn get_proof(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<ProofNode>, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.get_proof(&self.db, key)
        } else {
            Err(BonsaiStorageError::Trie("Tree not found".to_string()))
        }
    }

    pub(crate) fn get_identifiers(&self) -> Vec<Vec<u8>> {
        self.trees.keys().cloned().collect()
    }
}

/// A Starknet binary Merkle-Patricia tree with a specific root entry-point and storage.
///
/// This is used to update, mutate and access global Starknet state as well as individual contract
/// states.
///
/// For more information on how this functions internally, see [here](super::merkle_node).
pub struct MerkleTree<H: StarkHash> {
    /// The handle to the current root node could be hash if no modifications has been done
    /// since the last commit or in memory if there are some modifications.
    root_handle: NodeHandle,
    /// The last known root hash. Updated only each commit. (possibly outdated between two commits)
    root_hash: Felt,
    /// Identifier of the tree in the database.
    identifier: Vec<u8>,
    /// This storage is used to avoid modifying the underlying database each time during a commit.
    storage_nodes: NodesMapping,
    /// The id of the last node that has been added to the temporary storage.
    latest_node_id: NodeId,
    /// The list of nodes that should be removed from the underlying database during the next commit.
    death_row: Vec<TrieKey>,
    /// The list of leaves that have been modified during the current commit.
    cache_leaf_modified: HashMap<Vec<u8>, InsertOrRemove<Felt>>,
    /// The hasher used to hash the nodes.
    _hasher: PhantomData<H>,
}

// NB: #[derive(Clone)] does not work because it expands to an impl block which forces H: Clone, which Pedersen/Poseidon aren't.
#[cfg(feature = "bench")]
impl<H: StarkHash> Clone for MerkleTree<H> {
    fn clone(&self) -> Self {
        Self {
            root_handle: self.root_handle.clone(),
            root_hash: self.root_hash.clone(),
            identifier: self.identifier.clone(),
            storage_nodes: self.storage_nodes.clone(),
            latest_node_id: self.latest_node_id.clone(),
            death_row: self.death_row.clone(),
            cache_leaf_modified: self.cache_leaf_modified.clone(),
            _hasher: PhantomData,
        }
    }
}

#[derive(Clone, Debug, PartialEq, Eq)]
pub(crate) enum InsertOrRemove<T> {
    Insert(T),
    Remove,
}
enum NodeOrFelt<'a> {
    Node(&'a Node),
    Felt(Felt),
}

impl<H: StarkHash + Send + Sync> MerkleTree<H> {
    /// Less visible initialization for `MerkleTree<T>` as the main entry points should be
    /// [`MerkleTree::<RcNodeStorage>::load`] for persistent trees and [`MerkleTree::empty`] for
    /// transient ones.

    pub fn new<DB: BonsaiDatabase, ID: Id>(
        db: &mut KeyValueDB<DB, ID>,
        identifier: Vec<u8>,
    ) -> Result<Self, BonsaiStorageError<DB::DatabaseError>> {
        let nodes_mapping: HashMap<NodeId, Node> = HashMap::new();
        let root_node = db.get(&TrieKey::new(&identifier, TrieKeyType::Trie, &[]))?;
        let node = if let Some(root_node) = root_node {
            Node::decode(&mut root_node.as_slice())?
        } else {
            db.insert(
                &TrieKey::new(&identifier, TrieKeyType::Trie, &[]),
                &Node::Unresolved(Felt::ZERO).encode(),
                None,
            )?;
            Node::Unresolved(Felt::ZERO)
        };
        // SAFETY: The root node has been created just above
        let root = node.hash().unwrap();
        Ok(Self {
            root_handle: NodeHandle::Hash(root),
            root_hash: root,
            identifier,
            storage_nodes: NodesMapping(nodes_mapping),
            latest_node_id: NodeId(0),
            death_row: Vec::new(),
            cache_leaf_modified: HashMap::new(),
            _hasher: PhantomData,
        })
    }

    pub fn root_hash(&self) -> Felt {
        self.root_hash
    }

    pub fn cache_leaf_modified(&self) -> &HashMap<Vec<u8>, InsertOrRemove<Felt>> {
        &self.cache_leaf_modified
    }

    /// Remove all the modifications that have been done since the last commit.
    pub fn reset_to_last_commit<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &mut KeyValueDB<DB, ID>,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let node = self
            .get_trie_branch_in_db_from_path(db, &Path(BitVec::<u8, Msb0>::new()))?
            .ok_or(BonsaiStorageError::Trie(
                "root node doesn't exist in the storage".to_string(),
            ))?;
        let node_hash = node.hash().ok_or(BonsaiStorageError::Trie(
            "Root doesn't exist in the storage".to_string(),
        ))?;
        self.latest_node_id.reset();
        self.storage_nodes.0.clear();
        self.cache_leaf_modified.clear();
        self.root_handle = NodeHandle::Hash(node_hash);
        self.root_hash = node_hash;
        Ok(())
    }

    /// Calculate all the new hashes and the root hash.
    #[allow(clippy::type_complexity)]
    pub(crate) fn get_updates<DB: BonsaiDatabase>(
        &mut self,
    ) -> Result<Vec<(TrieKey, InsertOrRemove<Vec<u8>>)>, BonsaiStorageError<DB::DatabaseError>>
    {
        let mut updates = vec![];
        for node_key in mem::take(&mut self.death_row) {
            updates.push((node_key, InsertOrRemove::Remove));
        }

        let mut hashes = vec![];
        self.compute_root_hash::<DB>(&mut hashes)?;
        let root_hash = self.commit_subtree::<DB>(
            &mut updates,
            self.root_handle,
            Path(BitVec::new()),
            &mut hashes.drain(..),
        )?;

        for (key, value) in mem::take(&mut self.cache_leaf_modified) {
            updates.push((
                TrieKey::new(&self.identifier, TrieKeyType::Flat, &key),
                match value {
                    InsertOrRemove::Insert(value) => InsertOrRemove::Insert(value.encode()),
                    InsertOrRemove::Remove => InsertOrRemove::Remove,
                },
            ));
        }
        self.latest_node_id.reset();
        self.root_hash = root_hash;
        self.root_handle = NodeHandle::Hash(root_hash);
        Ok(updates)
    }

    fn get_node_or_felt<DB: BonsaiDatabase>(
        &self,
        node_handle: &NodeHandle,
    ) -> Result<NodeOrFelt, BonsaiStorageError<DB::DatabaseError>> {
        let node_id = match node_handle {
            NodeHandle::Hash(hash) => return Ok(NodeOrFelt::Felt(*hash)),
            NodeHandle::InMemory(root_id) => root_id,
        };
        let node = self
            .storage_nodes
            .0
            .get(node_id)
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch node in the temporary storage".to_string(),
            ))?;
        Ok(NodeOrFelt::Node(node))
    }

    fn compute_root_hash<DB: BonsaiDatabase>(
        &self,
        hashes: &mut Vec<Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        match self.get_node_or_felt::<DB>(&self.root_handle)? {
            NodeOrFelt::Felt(felt) => Ok(felt),
            NodeOrFelt::Node(node) => self.compute_hashes::<DB>(node, Path(BitVec::new()), hashes),
        }
    }

    /// Compute the hashes of all of the updated nodes in the merkle tree. This step
    /// is separate from [`commit_subtree`] as it is done in parallel using rayon.
    /// Computed hashes are pushed to the `hashes` vector, depth first.
    fn compute_hashes<DB: BonsaiDatabase>(
        &self,
        node: &Node,
        path: Path,
        hashes: &mut Vec<Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        use Node::*;

        match node {
            Unresolved(hash) => Ok(*hash),
            Binary(binary) => {
                // we check if we have one or two changed children

                let left_path = path.new_with_direction(Direction::Left);
                let node_left = self.get_node_or_felt::<DB>(&binary.left)?;
                let right_path = path.new_with_direction(Direction::Right);
                let node_right = self.get_node_or_felt::<DB>(&binary.right)?;

                let (left_hash, right_hash) = match (node_left, node_right) {
                    #[cfg(feature = "std")]
                    (NodeOrFelt::Node(left), NodeOrFelt::Node(right)) => {
                        // two children: use rayon
                        let (left, right) = rayon::join(
                            || self.compute_hashes::<DB>(left, left_path, hashes),
                            || {
                                let mut hashes = vec![];
                                let felt =
                                    self.compute_hashes::<DB>(right, right_path, &mut hashes)?;
                                Ok::<_, BonsaiStorageError<DB::DatabaseError>>((felt, hashes))
                            },
                        );
                        let (left_hash, (right_hash, hashes2)) = (left?, right?);
                        hashes.extend(hashes2);

                        (left_hash, right_hash)
                    }
                    (left, right) => {
                        let left_hash = match left {
                            NodeOrFelt::Felt(felt) => felt,
                            NodeOrFelt::Node(node) => {
                                self.compute_hashes::<DB>(node, left_path, hashes)?
                            }
                        };
                        let right_hash = match right {
                            NodeOrFelt::Felt(felt) => felt,
                            NodeOrFelt::Node(node) => {
                                self.compute_hashes::<DB>(node, right_path, hashes)?
                            }
                        };
                        (left_hash, right_hash)
                    }
                };

                let hash = H::hash(&left_hash, &right_hash);
                hashes.push(hash);
                Ok(hash)
            }

            Edge(edge) => {
                let mut child_path = path.clone();
                child_path.0.extend(&edge.path.0);
                let child_hash = match self.get_node_or_felt::<DB>(&edge.child)? {
                    NodeOrFelt::Felt(felt) => felt,
                    NodeOrFelt::Node(node) => {
                        self.compute_hashes::<DB>(node, child_path, hashes)?
                    }
                };

                let mut bytes = [0u8; 32];
                bytes.view_bits_mut::<Msb0>()[256 - edge.path.0.len()..]
                    .copy_from_bitslice(&edge.path.0);

                let felt_path = Felt::from_bytes_be(&bytes);
                let mut length = [0; 32];
                // Safe as len() is guaranteed to be <= 251
                length[31] = edge.path.0.len() as u8;

                let length = Felt::from_bytes_be(&length);
                let hash = H::hash(&child_hash, &felt_path) + length;
                hashes.push(hash);
                Ok(hash)
            }
        }
    }

    /// Persists any changes in this subtree to storage.
    ///
    /// This necessitates recursively calculating the hash of, and
    /// in turn persisting, any changed child nodes. This is necessary
    /// as the parent node's hash relies on its children hashes.
    /// Hash computation is done in parallel with [`compute_hashes`] beforehand.
    ///
    /// In effect, the entire tree gets persisted.
    ///
    /// # Arguments
    ///
    /// * `node_handle` - The top node from the subtree to commit.
    /// * `hashes` - The precomputed hashes for the subtree as returned by [`compute_hashes`].
    ///   The order is depth first, left to right.
    ///
    /// # Panics
    ///
    /// Panics if the precomputed `hashes` do not match the length of the modified subtree.
    fn commit_subtree<DB: BonsaiDatabase>(
        &mut self,
        updates: &mut Vec<(TrieKey, InsertOrRemove<Vec<u8>>)>,
        node_handle: NodeHandle,
        path: Path,
        hashes: &mut impl Iterator<Item = Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        let node_id = match node_handle {
            NodeHandle::Hash(hash) => return Ok(hash),
            NodeHandle::InMemory(root_id) => root_id,
        };

        match self
            .storage_nodes
            .0
            .remove(&node_id)
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch node in the temporary storage".to_string(),
            ))? {
            Node::Unresolved(hash) => {
                if path.0.is_empty() {
                    updates.push((
                        TrieKey::new(&self.identifier, TrieKeyType::Trie, &[]),
                        InsertOrRemove::Insert(Node::Unresolved(hash).encode()),
                    ));
                    Ok(hash)
                } else {
                    Ok(hash)
                }
            }
            Node::Binary(mut binary) => {
                let left_path = path.new_with_direction(Direction::Left);
                let left_hash =
                    self.commit_subtree::<DB>(updates, binary.left, left_path, hashes)?;
                let right_path = path.new_with_direction(Direction::Right);
                let right_hash =
                    self.commit_subtree::<DB>(updates, binary.right, right_path, hashes)?;
                let hash = hashes.next().expect("mismatched hash state");
                binary.hash = Some(hash);
                binary.left = NodeHandle::Hash(left_hash);
                binary.right = NodeHandle::Hash(right_hash);
                let key_bytes: Vec<u8> = path.into();
                updates.push((
                    TrieKey::new(&self.identifier, TrieKeyType::Trie, &key_bytes),
                    InsertOrRemove::Insert(Node::Binary(binary).encode()),
                ));
                Ok(hash)
            }
            Node::Edge(mut edge) => {
                let mut child_path = path.clone();
                child_path.0.extend(&edge.path.0);
                let child_hash =
                    self.commit_subtree::<DB>(updates, edge.child, child_path, hashes)?;
                let hash = hashes.next().expect("mismatched hash state");
                edge.hash = Some(hash);
                edge.child = NodeHandle::Hash(child_hash);
                let key_bytes: Vec<u8> = path.into();
                updates.push((
                    TrieKey::new(&self.identifier, TrieKeyType::Trie, &key_bytes),
                    InsertOrRemove::Insert(Node::Edge(edge).encode()),
                ));
                Ok(hash)
            }
        }
    }

    /// Sets the value of a key. To delete a key, set the value to [Felt::ZERO].
    ///
    /// # Arguments
    ///
    /// * `key` - The key to set.
    /// * `value` - The value to set.
    pub fn set<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &mut KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
        value: Felt,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        if value == Felt::ZERO {
            return self.delete_leaf(db, key);
        }
        let key_bytes = bitslice_to_bytes(key);
        if let Some(InsertOrRemove::Insert(value_db)) = self.cache_leaf_modified.get(&key_bytes) {
            if &value == value_db {
                return Ok(());
            }
        }
        if let Some(value_db) = db.get(&TrieKey::new(
            &self.identifier,
            TrieKeyType::Flat,
            &key_bytes,
        ))? {
            if value == Felt::decode(&mut value_db.as_slice()).unwrap() {
                return Ok(());
            }
        }
        let path = self.preload_nodes(db, key)?;
        // There are three possibilities.
        //
        // 1. The leaf exists, in which case we simply change its value.
        //
        // 2. The tree is empty, we insert the new leaf and the root becomes an edge node connecting to it.
        //
        // 3. The leaf does not exist, and the tree is not empty. The final node in the traversal will be an
        //    edge node who's path diverges from our new leaf node's.
        //
        //    This edge must be split into a new subtree containing both the existing edge's child and the
        //    new leaf. This requires an edge followed by a binary node and then further edges to both the
        //    current child and the new leaf. Any of these new edges may also end with an empty path in
        //    which case they should be elided. It depends on the common path length of the current edge
        //    and the new leaf i.e. the split may be at the first bit (in which case there is no leading
        //    edge), or the split may be in the middle (requires both leading and post edges), or the
        //    split may be the final bit (no post edge).
        use Node::*;
        match path.last() {
            Some(node_id) => {
                let mut nodes_to_add = Vec::new();
                self.storage_nodes.0.entry(*node_id).and_modify(|node| {
                    match node {
                        Edge(edge) => {
                            let common = edge.common_path(key);
                            // Height of the binary node
                            let branch_height = edge.height as usize + common.len();
                            if branch_height == key.len() {
                                edge.child = NodeHandle::Hash(value);
                                // The leaf already exists, we simply change its value.
                                self.cache_leaf_modified
                                    .insert(key_bytes, InsertOrRemove::Insert(value));
                                return;
                            }
                            // Height of the binary node's children
                            let child_height = branch_height + 1;

                            // Path from binary node to new leaf
                            let new_path = key[child_height..].to_bitvec();
                            // Path from binary node to existing child
                            let old_path = edge.path.0[common.len() + 1..].to_bitvec();

                            // The new leaf branch of the binary node.
                            // (this may be edge -> leaf, or just leaf depending).
                            self.cache_leaf_modified
                                .insert(key_bytes, InsertOrRemove::Insert(value));

                            let new = if new_path.is_empty() {
                                NodeHandle::Hash(value)
                            } else {
                                let new_edge = Node::Edge(EdgeNode {
                                    hash: None,
                                    height: child_height as u64,
                                    path: Path(new_path),
                                    child: NodeHandle::Hash(value),
                                });
                                let edge_id = self.latest_node_id.next_id();
                                nodes_to_add.push((edge_id, new_edge));
                                NodeHandle::InMemory(edge_id)
                            };

                            // The existing child branch of the binary node.
                            let old = if old_path.is_empty() {
                                edge.child
                            } else {
                                let old_edge = Node::Edge(EdgeNode {
                                    hash: None,
                                    height: child_height as u64,
                                    path: Path(old_path),
                                    child: edge.child,
                                });
                                let edge_id = self.latest_node_id.next_id();
                                nodes_to_add.push((edge_id, old_edge));
                                NodeHandle::InMemory(edge_id)
                            };

                            let new_direction = Direction::from(key[branch_height]);
                            let (left, right) = match new_direction {
                                Direction::Left => (new, old),
                                Direction::Right => (old, new),
                            };

                            let branch = Node::Binary(BinaryNode {
                                hash: None,
                                height: branch_height as u64,
                                left,
                                right,
                            });

                            // We may require an edge leading to the binary node.
                            let new_node = if common.is_empty() {
                                branch
                            } else {
                                let branch_id = self.latest_node_id.next_id();
                                nodes_to_add.push((branch_id, branch));

                                Node::Edge(EdgeNode {
                                    hash: None,
                                    height: edge.height,
                                    path: Path(common.to_bitvec()),
                                    child: NodeHandle::InMemory(branch_id),
                                })
                            };
                            let path = key[..edge.height as usize].to_bitvec();
                            let key_bytes =
                                [&[path.len() as u8], path.into_vec().as_slice()].concat();
                            self.death_row.push(TrieKey::Trie(key_bytes));
                            *node = new_node;
                        }
                        Binary(binary) => {
                            if (binary.height + 1) as usize == key.len() {
                                let direction = Direction::from(key[binary.height as usize]);
                                match direction {
                                    Direction::Left => binary.left = NodeHandle::Hash(value),
                                    Direction::Right => binary.right = NodeHandle::Hash(value),
                                };
                            }
                        }
                        _ => {}
                    }
                });
                for (id, node) in nodes_to_add {
                    self.storage_nodes.0.insert(id, node);
                }
                Ok(())
            }
            None => {
                // Getting no travel nodes implies that the tree is empty.
                //
                // Create a new leaf node with the value, and the root becomes
                // an edge node connecting to the leaf.
                let edge = Node::Edge(EdgeNode {
                    hash: None,
                    height: 0,
                    path: Path(key.to_bitvec()),
                    child: NodeHandle::Hash(value),
                });
                self.storage_nodes
                    .0
                    .insert(self.latest_node_id.next_id(), edge);

                self.root_handle = NodeHandle::InMemory(self.latest_node_id);

                let key_bytes = bitslice_to_bytes(key);
                self.cache_leaf_modified
                    .insert(key_bytes, InsertOrRemove::Insert(value));
                Ok(())
            }
        }
    }

    /// Deletes a leaf node from the tree.
    ///
    /// This is not an external facing API; the functionality is instead accessed by calling
    /// [`MerkleTree::set`] with value set to [`Felt::ZERO`].
    ///
    /// # Arguments
    ///
    /// * `key` - The key to delete.
    fn delete_leaf<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &mut KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        // Algorithm explanation:
        //
        // The leaf's parent node is either an edge, or a binary node.
        // If it's an edge node, then it must also be deleted. And its parent
        // must be a binary node. In either case we end up with a binary node
        // who's one child is deleted. This changes the binary to an edge node.
        //
        // Note that its possible that there is no binary node -- if the resulting tree would be empty.
        //
        // This new edge node may need to merge with the old binary node's parent node
        // and other remaining child node -- if they're also edges.
        //
        // Then we are done.
        let key_bytes = bitslice_to_bytes(key);
        if db
            .get(&TrieKey::new(
                &self.identifier,
                TrieKeyType::Flat,
                &key_bytes,
            ))?
            .is_none()
            && !self.cache_leaf_modified.contains_key(&key_bytes)
        {
            return Ok(());
        }
        self.cache_leaf_modified
            .insert(key_bytes.clone(), InsertOrRemove::Remove);

        let path = self.preload_nodes(db, key)?;

        let mut last_binary_path = Path(key.to_bitvec());

        // Go backwards until we hit a branch node.
        let mut node_iter = path.into_iter().rev().skip_while(|node| {
            // SAFETY: Has been populate by preload_nodes just above
            let node = self.storage_nodes.0.get(node).unwrap();
            match node {
                Node::Unresolved(_) => {}
                Node::Binary(_) => {}
                Node::Edge(edge) => {
                    for _ in 0..edge.path.0.len() {
                        last_binary_path.0.pop();
                    }
                    let mut new_path = Path(BitVec::new());
                    for i in last_binary_path.0.iter() {
                        new_path.0.push(*i);
                    }
                    last_binary_path = new_path;
                    let path: Vec<u8> = (&last_binary_path).into();
                    self.death_row
                        .push(TrieKey::new(&self.identifier, TrieKeyType::Trie, &path));
                }
            }
            !node.is_binary()
        });
        let branch_node = node_iter.next();
        let parent_branch_node = node_iter.next();
        match branch_node {
            Some(node_id) => {
                let new_edge =
                    {
                        let node = self.storage_nodes.0.get_mut(&node_id).ok_or(
                            BonsaiStorageError::Trie("Node not found in memory".to_string()),
                        )?;
                        // SAFETY: This node must be a binary node due to the iteration condition.
                        let binary = node.as_binary().unwrap();
                        let (direction, height) =
                            { (binary.direction(key).invert(), binary.height) };
                        last_binary_path.0.pop();
                        last_binary_path.0.push(bool::from(direction));
                        // Create an edge node to replace the old binary node
                        // i.e. with the remaining child (note the direction invert),
                        //      and a path of just a single bit.
                        let path = Path(once(bool::from(direction)).collect::<BitVec<_, _>>());
                        let mut edge = EdgeNode {
                            hash: None,
                            height,
                            path,
                            child: match direction {
                                Direction::Left => binary.left,
                                Direction::Right => binary.right,
                            },
                        };

                        // Merge the remaining child if it's an edge.
                        self.merge_edges::<DB, ID>(&mut edge, db, &last_binary_path)?;
                        edge
                    };
                // Check the parent of the new edge. If it is also an edge, then they must merge.
                if let Some(parent_node_id) = parent_branch_node {
                    // Get a mutable reference to the parent node to merge them
                    let parent_node = self.storage_nodes.0.get_mut(&parent_node_id).ok_or(
                        BonsaiStorageError::Trie("Node not found in memory".to_string()),
                    )?;
                    if let Node::Edge(parent_edge) = parent_node {
                        parent_edge.path.0.extend_from_bitslice(&new_edge.path.0);
                        parent_edge.child = new_edge.child;
                    } else {
                        self.storage_nodes.0.insert(node_id, Node::Edge(new_edge));
                    }
                } else {
                    self.storage_nodes.0.insert(node_id, Node::Edge(new_edge));
                }
            }
            None => {
                // We reached the root without a hitting binary node. The new tree
                // must therefore be empty.
                self.latest_node_id.next_id();
                self.storage_nodes
                    .0
                    .insert(self.latest_node_id, Node::Unresolved(Felt::ZERO));
                self.root_handle = NodeHandle::InMemory(self.latest_node_id);
                self.root_hash = Felt::ZERO;
                return Ok(());
            }
        };
        Ok(())
    }

    /// Returns the value stored at key, or `None` if it does not exist.
    ///
    /// # Arguments
    ///
    /// * `key` - The key of the value to get.
    ///
    /// # Returns
    ///
    /// The value of the key.
    pub fn get<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let key = bitslice_to_bytes(key);
        if let Some(value) = self.cache_leaf_modified.get(&key) {
            match value {
                InsertOrRemove::Remove => return Ok(None),
                InsertOrRemove::Insert(value) => return Ok(Some(*value)),
            }
        }
        db.get(&TrieKey::new(&self.identifier, TrieKeyType::Flat, &key))
            .map(|r| r.map(|opt| Felt::decode(&mut opt.as_slice()).unwrap()))
    }

    pub fn contains<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<bool, BonsaiStorageError<DB::DatabaseError>> {
        let key = bitslice_to_bytes(key);
        if let Some(value) = self.cache_leaf_modified.get(&key) {
            match value {
                InsertOrRemove::Remove => return Ok(false),
                InsertOrRemove::Insert(_) => return Ok(true),
            }
        }
        db.contains(&TrieKey::new(&self.identifier, TrieKeyType::Flat, &key))
    }

    /// Returns the list of nodes along the path.
    ///
    /// if it exists, or down to the node which proves that the key does not exist.
    ///
    /// The nodes are returned in order, root first.
    ///
    /// Verification is performed by confirming that:
    ///   1. the chain follows the path of `key`, and
    ///   2. the hashes are correct, and
    ///   3. the root hash matches the known root
    ///
    /// # Arguments
    ///
    /// * `key` - The key to get the merkle proof of.
    ///
    /// # Returns
    ///
    /// The merkle proof and all the child nodes hashes.
    pub fn get_proof<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<ProofNode>, BonsaiStorageError<DB::DatabaseError>> {
        let mut nodes = Vec::with_capacity(251);
        let mut node = match self.root_handle {
            NodeHandle::Hash(_) => {
                let node = self
                    .get_trie_branch_in_db_from_path(db, &Path(BitVec::<u8, Msb0>::new()))?
                    .ok_or(BonsaiStorageError::Trie(
                        "Couldn't fetch root node in db".to_string(),
                    ))?;
                if node.is_empty() {
                    return Ok(Vec::new());
                }
                node
            }
            NodeHandle::InMemory(root_id) => self
                .storage_nodes
                .0
                .get(&root_id)
                .ok_or(BonsaiStorageError::Trie(
                    "Couldn't fetch root node in the temporary storage".to_string(),
                ))?
                .clone(),
        };
        loop {
            match node {
                Node::Edge(edge) => {
                    let child_path = key[..edge.height as usize + edge.path.0.len()].to_bitvec();
                    let child_node = match edge.child {
                        NodeHandle::Hash(hash) => {
                            let node =
                                self.get_trie_branch_in_db_from_path(db, &Path(child_path))?;
                            if let Some(node) = node {
                                node
                            } else {
                                nodes.push(ProofNode::Edge {
                                    child: hash,
                                    path: edge.path.clone(),
                                });
                                return Ok(nodes);
                            }
                        }
                        NodeHandle::InMemory(child_id) => self
                            .storage_nodes
                            .0
                            .get(&child_id)
                            .ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch child node in the temporary storage".to_string(),
                            ))?
                            .clone(),
                    };
                    nodes.push(ProofNode::Edge {
                        child: child_node.hash().ok_or(BonsaiStorageError::Trie(
                            "Couldn't fetch child node in the temporary storage".to_string(),
                        ))?,
                        path: edge.path.clone(),
                    });
                    if edge.path_matches(key) {
                        node = child_node;
                    } else {
                        return Ok(nodes);
                    }
                    if edge.common_path(key) == key {
                        return Ok(nodes);
                    }
                }
                Node::Binary(binary) => {
                    let next_direction = key
                        .get(binary.height as usize)
                        .map(|b| Direction::from(*b))
                        .ok_or(BonsaiStorageError::Trie("Key too short".to_string()))?;
                    let next = binary.get_child(next_direction);
                    let next_path = key[..binary.height as usize + 1].to_bitvec();
                    let next_node = match next {
                        NodeHandle::Hash(_) => self
                            .get_trie_branch_in_db_from_path(db, &Path(next_path))?
                            .ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch next node in db".to_string(),
                            ))?,
                        NodeHandle::InMemory(next_id) => self
                            .storage_nodes
                            .0
                            .get(&next_id)
                            .ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch next node in the temporary storage".to_string(),
                            ))?
                            .clone(),
                    };
                    let other = binary.get_child(next_direction.invert());
                    let other_hash = match other {
                        NodeHandle::Hash(hash) => hash,
                        NodeHandle::InMemory(other_id) => {
                            let other_node = self
                                .storage_nodes
                                .0
                                .get(&other_id)
                                .ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch other node in the temporary storage"
                                        .to_string(),
                                ))?
                                .clone();
                            other_node.hash().ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch other node in the temporary storage".to_string(),
                            ))?
                        }
                    };
                    match next_direction {
                        Direction::Left => {
                            nodes.push(ProofNode::Binary {
                                left: next_node.hash().ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch next node in the temporary storage".to_string(),
                                ))?,
                                right: other_hash,
                            });
                        }
                        Direction::Right => {
                            nodes.push(ProofNode::Binary {
                                left: other_hash,
                                right: next_node.hash().ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch next node in the temporary storage".to_string(),
                                ))?,
                            });
                        }
                    }
                    node = next_node;
                }
                Node::Unresolved(hash) => {
                    nodes.push(ProofNode::Edge {
                        child: hash,
                        path: Path(BitVec::<u8, Msb0>::new()),
                    });
                    return Ok(nodes);
                }
            }
        }
    }

    /// preload_nodes from the current root towards the destination [Leaf](Node::Leaf) node.
    /// If the destination node exists, it will be the final node in the list.
    ///
    /// This means that the final node will always be either a the destination [Leaf](Node::Leaf)
    /// node, or an [Edge](Node::Edge) node who's path suffix does not match the leaf's path.
    ///
    /// The final node can __not__ be a [Binary](Node::Binary) node since it would always be
    /// possible to continue on towards the destination. Nor can it be an
    /// [Unresolved](Node::Unresolved) node since this would be resolved to check if we can
    /// travel further.
    ///
    /// # Arguments
    ///
    /// * `dst` - The node to get to.
    ///
    /// # Returns
    ///
    /// The list of nodes along the path.
    fn preload_nodes<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &mut KeyValueDB<DB, ID>,
        dst: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<NodeId>, BonsaiStorageError<DB::DatabaseError>> {
        let mut nodes = Vec::with_capacity(251);
        let node_id = match self.root_handle {
            NodeHandle::Hash(_) => {
                let node = self
                    .get_trie_branch_in_db_from_path(db, &Path(BitVec::<u8, Msb0>::new()))?
                    .ok_or(BonsaiStorageError::Trie(
                        "Couldn't fetch root node in db".to_string(),
                    ))?;
                if node.is_empty() {
                    return Ok(Vec::new());
                }
                self.latest_node_id.next_id();
                self.root_handle = NodeHandle::InMemory(self.latest_node_id);
                self.storage_nodes.0.insert(self.latest_node_id, node);
                nodes.push(self.latest_node_id);
                self.latest_node_id
            }
            NodeHandle::InMemory(root_id) => {
                nodes.push(root_id);
                root_id
            }
        };
        self.preload_nodes_subtree(
            db,
            dst,
            node_id,
            Path(BitVec::<u8, Msb0>::new()),
            &mut nodes,
        )?;
        Ok(nodes)
    }

    fn preload_nodes_subtree<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &mut KeyValueDB<DB, ID>,
        dst: &BitSlice<u8, Msb0>,
        root_id: NodeId,
        mut path: Path,
        nodes: &mut Vec<NodeId>,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let node = self
            .storage_nodes
            .0
            .get(&root_id)
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch node in the temporary storage".to_string(),
            ))?
            .clone();
        match node {
            // We are in a case where the trie is empty and so there is nothing to preload.
            Node::Unresolved(_hash) => Ok(()),
            // We are checking which side of the binary we should load in memory (if we don't have it already)
            // We load this "child-side" node in the memory and refer his memory handle in the binary node.
            // We also add the "child-side" node in the list that accumulate all the nodes we want to preload.
            // We override the binary node in the memory with this new version that has the "child-side" memory handle
            // instead of the hash.
            // We call recursively the function with the "child-side" node.
            Node::Binary(mut binary_node) => {
                let next_direction = binary_node.direction(dst);
                path.0.push(bool::from(next_direction));
                let next = binary_node.get_child(next_direction);
                match next {
                    NodeHandle::Hash(_) => {
                        let node = self.get_trie_branch_in_db_from_path(db, &path)?;
                        if let Some(node) = node {
                            self.latest_node_id.next_id();
                            self.storage_nodes.0.insert(self.latest_node_id, node);
                            nodes.push(self.latest_node_id);
                            match next_direction {
                                Direction::Left => {
                                    binary_node.left = NodeHandle::InMemory(self.latest_node_id)
                                }
                                Direction::Right => {
                                    binary_node.right = NodeHandle::InMemory(self.latest_node_id)
                                }
                            };
                            self.storage_nodes
                                .0
                                .insert(root_id, Node::Binary(binary_node));
                            self.preload_nodes_subtree(db, dst, self.latest_node_id, path, nodes)
                        } else {
                            Ok(())
                        }
                    }
                    NodeHandle::InMemory(next_id) => {
                        nodes.push(next_id);
                        self.preload_nodes_subtree(db, dst, next_id, path, nodes)
                    }
                }
            }
            // If the edge node match the path we want to preload then we load the child node in memory (if we don't have it already)
            // and we override the edge node in the memory with this new version that has the child memory handle instead of the hash.
            // We also add the child node in the list that accumulate all the nodes we want to preload.
            // We call recursively the function with the child node.
            Node::Edge(mut edge_node) if edge_node.path_matches(dst) => {
                path.0.extend_from_bitslice(&edge_node.path.0);
                if path.0 == dst {
                    return Ok(());
                }
                let next = edge_node.child;
                match next {
                    NodeHandle::Hash(_) => {
                        let node = self.get_trie_branch_in_db_from_path(db, &path)?;
                        if let Some(node) = node {
                            self.latest_node_id.next_id();
                            self.storage_nodes.0.insert(self.latest_node_id, node);
                            nodes.push(self.latest_node_id);
                            edge_node.child = NodeHandle::InMemory(self.latest_node_id);
                            self.storage_nodes.0.insert(root_id, Node::Edge(edge_node));
                            self.preload_nodes_subtree(db, dst, self.latest_node_id, path, nodes)
                        } else {
                            Ok(())
                        }
                    }
                    NodeHandle::InMemory(next_id) => {
                        nodes.push(next_id);
                        self.preload_nodes_subtree(db, dst, next_id, path, nodes)
                    }
                }
            }
            // We are in a case where the edge node doesn't match the path we want to preload so we return nothing.
            Node::Edge(_) => Ok(()),
        }
    }

    /// Get the node of the trie that corresponds to the path.
    fn get_trie_branch_in_db_from_path<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        path: &Path,
    ) -> Result<Option<Node>, BonsaiStorageError<DB::DatabaseError>> {
        let path: Vec<u8> = path.into();
        db.get(&TrieKey::new(&self.identifier, TrieKeyType::Trie, &path))?
            .map(|node| {
                Node::decode(&mut node.as_slice()).map_err(|err| {
                    BonsaiStorageError::Trie(format!("Couldn't decode node: {}", err))
                })
            })
            .map_or(Ok(None), |r| r.map(Some))
    }

    /// This is a convenience function which merges the edge node with its child __iff__ it is also
    /// an edge.
    ///
    /// Does nothing if the child is not also an edge node.
    ///
    /// This can occur when mutating the tree (e.g. deleting a child of a binary node), and is an
    /// illegal state (since edge nodes __must be__ maximal subtrees).
    ///
    /// # Arguments
    ///
    /// * `parent` - The parent node to merge the child with.
    fn merge_edges<DB: BonsaiDatabase, ID: Id>(
        &self,
        parent: &mut EdgeNode,
        db: &KeyValueDB<DB, ID>,
        path: &Path,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let child_node = match parent.child {
            NodeHandle::Hash(_) => {
                let node = self.get_trie_branch_in_db_from_path(db, path)?;
                if let Some(node) = node {
                    node
                } else {
                    return Ok(());
                }
            }
            NodeHandle::InMemory(child_id) => self
                .storage_nodes
                .0
                .get(&child_id)
                .ok_or(BonsaiStorageError::Trie(
                    "Couldn't fetch node in memory".to_string(),
                ))?
                .clone(),
        };
        if let Node::Edge(child_edge) = child_node {
            parent.path.0.extend_from_bitslice(&child_edge.path.0);
            parent.child = child_edge.child;
        }
        Ok(())
    }

    /// Function that come from pathfinder_merkle_tree::merkle_tree::MerkleTree
    /// Verifies that the key `key` with value `value` is indeed part of the MPT that has root
    /// `root`, given `proofs`.
    /// Supports proofs of non-membership as well as proof of membership: this function returns
    /// an enum corresponding to the membership of `value`, or returns `None` in case of a hash mismatch.
    /// The algorithm follows this logic:
    /// 1. init expected_hash <- root hash
    /// 2. loop over nodes: current <- nodes[i]
    ///    1. verify the current node's hash matches expected_hash (if not then we have a bad proof)
    ///    2. move towards the target - if current is:
    ///       1. binary node then choose the child that moves towards the target, else if
    ///       2. edge node then check the path against the target bits
    ///          1. If it matches then proceed with the child, else
    ///          2. if it does not match then we now have a proof that the target does not exist
    ///    3. nibble off target bits according to which child you got in (2). If all bits are gone then you
    ///       have reached the target and the child hash is the value you wanted and the proof is complete.
    ///    4. set expected_hash <- to the child hash
    /// 3. check that the expected_hash is `value` (we should've reached the leaf)
    pub fn verify_proof(
        root: Felt,
        key: &BitSlice<u8, Msb0>,
        value: Felt,
        proofs: &[ProofNode],
    ) -> Option<Membership> {
        // Protect from ill-formed keys
        if key.len() > 251 {
            return None;
        }

        let mut expected_hash = root;
        let mut remaining_path: &BitSlice<u8, Msb0> = key;

        for proof_node in proofs.iter() {
            // Hash mismatch? Return None.
            if proof_node.hash::<H>() != expected_hash {
                return None;
            }
            match proof_node {
                ProofNode::Binary { left, right } => {
                    // Direction will always correspond to the 0th index
                    // because we're removing bits on every iteration.
                    let direction = Direction::from(remaining_path[0]);

                    // Set the next hash to be the left or right hash,
                    // depending on the direction
                    expected_hash = match direction {
                        Direction::Left => *left,
                        Direction::Right => *right,
                    };

                    // Advance by a single bit
                    remaining_path = &remaining_path[1..];
                }
                ProofNode::Edge { child, path } => {
                    if path.0 != remaining_path[..path.0.len()] {
                        // If paths don't match, we've found a proof of non membership because we:
                        // 1. Correctly moved towards the target insofar as is possible, and
                        // 2. hashing all the nodes along the path does result in the root hash, which means
                        // 3. the target definitely does not exist in this tree
                        return Some(Membership::NonMember);
                    }

                    // Set the next hash to the child's hash
                    expected_hash = *child;

                    // Advance by the whole edge path
                    remaining_path = &remaining_path[path.0.len()..];
                }
            }
        }

        // At this point, we should reach `value` !
        if expected_hash == value {
            Some(Membership::Member)
        } else {
            // Hash mismatch. Return `None`.
            None
        }
    }

    #[cfg(test)]
    #[allow(dead_code)]
    fn display(&self) {
        match self.root_handle {
            NodeHandle::Hash(hash) => {
                trace!("root is hash: {:?}", hash);
            }
            NodeHandle::InMemory(root_id) => {
                trace!("root is node: {:?}", root_id);
                self.print(&root_id);
            }
        }
    }

    #[cfg(test)]
    #[allow(dead_code)]
    fn print(&self, head: &NodeId) {
        use Node::*;

        let current_tmp = self.storage_nodes.0.get(head).unwrap().clone();
        trace!("bonsai_node {:?} = {:?}", head, current_tmp);

        match current_tmp {
            Unresolved(hash) => {
                trace!("Unresolved: {:?}", hash);
            }
            Binary(binary) => {
                match &binary.get_child(Direction::Left) {
                    NodeHandle::Hash(hash) => {
                        trace!("left is hash {:?}", hash);
                    }
                    NodeHandle::InMemory(left_id) => {
                        self.print(left_id);
                    }
                }
                match &binary.get_child(Direction::Right) {
                    NodeHandle::Hash(hash) => {
                        trace!("right is hash {:?}", hash);
                    }
                    NodeHandle::InMemory(right_id) => {
                        self.print(right_id);
                    }
                }
            }
            Edge(edge) => match &edge.child {
                NodeHandle::Hash(hash) => {
                    trace!("child is hash {:?}", hash);
                }
                NodeHandle::InMemory(child_id) => {
                    self.print(child_id);
                }
            },
        };
    }
}

pub(crate) fn bitslice_to_bytes(bitslice: &BitSlice<u8, Msb0>) -> Vec<u8> {
    [&[bitslice.len() as u8], bitslice.to_bitvec().as_raw_slice()].concat()
}

pub(crate) fn bytes_to_bitvec(bytes: &[u8]) -> BitVec<u8, Msb0> {
    BitSlice::from_slice(&bytes[1..]).to_bitvec()
}

#[cfg(test)]
#[cfg(all(test, feature = "std"))]
mod tests {
    use bitvec::{order::Msb0, vec::BitVec, view::BitView};
    use indexmap::IndexMap;
    use starknet_types_core::{felt::Felt, hash::Pedersen};

    use crate::{
        databases::{create_rocks_db, RocksDB, RocksDBConfig},
        id::BasicId,
        BonsaiStorage, BonsaiStorageConfig,
    };

    #[test_log::test]
    // The whole point of this test is to make sure it is possible to reconstruct the original
    // keys from the data present in the db.
    fn test_key_retrieval() {
        let tempdir = tempfile::tempdir().unwrap();
        let rocksdb = create_rocks_db(tempdir.path()).unwrap();
        let db = RocksDB::new(&rocksdb, RocksDBConfig::default());
        let mut bonsai =
            BonsaiStorage::<BasicId, _, Pedersen>::new(db, BonsaiStorageConfig::default()).unwrap();

        let block_0 = vec![
            (
                str_to_felt_bytes(
                    "0x031c887d82502ceb218c06ebb46198da3f7b92864a8223746bc836dda3e34b52",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000065",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00cfc2e2866fd08bfb4ac73b70e0c136e326ae18fc797a2c090c8811c695577e",
                        ),
                        str_to_felt_bytes(
                            "0x05f1dd5a5aef88e0498eeca4e7b2ea0fa7110608c11531278742f0b5499af4b3",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05aee31408163292105d875070f98cb48275b8c87e80380b78d30647e05854d5",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05fac6815fddf6af1ca5e592359862ede14f171e1544fd9e792288164097c35d",
                        ),
                        str_to_felt_bytes(
                            "0x00299e2f4b5a873e95e65eb03d31e532ea2cde43b498b50cd3161145db5542a5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05fac6815fddf6af1ca5e592359862ede14f171e1544fd9e792288164097c35e",
                        ),
                        str_to_felt_bytes(
                            "0x03d6897cf23da3bf4fd35cc7a43ccaf7c5eaf8f7c5b9031ac9b09a929204175f",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x06ee3440b08a9c805305449ec7f7003f27e9f7e287b83610952ec36bdc5a6bae",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x01e2cd4b3588e8f6f9c4e89fb0e293bf92018c96d7a93ee367d29a284223b6ff",
                        ),
                        str_to_felt_bytes(
                            "0x071d1e9d188c784a0bde95c1d508877a0d93e9102b37213d1e13f3ebc54a7751",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0449908c349e90f81ab13042b1e49dc251eb6e3e51092d9a40f86859f7f415b0",
                        ),
                        str_to_felt_bytes(
                            "0x06cb6104279e754967a721b52bcf5be525fdc11fa6db6ef5c3a4db832acf7804",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x048cba68d4e86764105adcdcf641ab67b581a55a4f367203647549c8bf1feea2",
                        ),
                        str_to_felt_bytes(
                            "0x0362d24a3b030998ac75e838955dfee19ec5b6eceb235b9bfbeccf51b6304d0b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05bdaf1d47b176bfcd1114809af85a46b9c4376e87e361d86536f0288a284b65",
                        ),
                        str_to_felt_bytes(
                            "0x028dff6722aa73281b2cf84cac09950b71fa90512db294d2042119abdd9f4b87",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05bdaf1d47b176bfcd1114809af85a46b9c4376e87e361d86536f0288a284b66",
                        ),
                        str_to_felt_bytes(
                            "0x057a8f8a019ccab5bfc6ff86c96b1392257abb8d5d110c01d326b94247af161c",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05f750dc13ed239fa6fc43ff6e10ae9125a33bd05ec034fc3bb4dd168df3505f",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x0735596016a37ee972c42adef6a3cf628c19bb3794369c65d2c82ba034aecf2c",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000064",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x002f50710449a06a9fa789b3c029a63bd0b1f722f46505828a9f815cf91b31d8",
                        ),
                        str_to_felt_bytes(
                            "0x02a222e62eabe91abdb6838fa8b267ffe81a6eb575f61e96ec9aa4460c0925a2",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x020cfa74ee3564b4cd5435cdace0f9c4d43b939620e4a0bb5076105df0a626c6",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x000000000000000000000000000000000000000000000000000000000000022b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0313ad57fdf765addc71329abf8d74ac2bce6d46da8c2b9b82255a5076620300",
                        ),
                        str_to_felt_bytes(
                            "0x04e7e989d58a17cd279eca440c5eaa829efb6f9967aaad89022acbe644c39b36",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0313ad57fdf765addc71329abf8d74ac2bce6d46da8c2b9b82255a5076620301",
                        ),
                        str_to_felt_bytes(
                            "0x0453ae0c9610197b18b13645c44d3d0a407083d96562e8752aab3fab616cecb0",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05aee31408163292105d875070f98cb48275b8c87e80380b78d30647e05854d5",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x06cf6c2f36d36b08e591e4489e92ca882bb67b9c39a3afccf011972a8de467f0",
                        ),
                        str_to_felt_bytes(
                            "0x07ab344d88124307c07b56f6c59c12f4543e9c96398727854a322dea82c73240",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x031c887d82502ceb218c06ebb46198da3f7b92864a8223746bc836dda3e34b52",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x00df28e613c065616a2e79ca72f9c1908e17b8c913972a9993da77588dc9cae9",
                        ),
                        str_to_felt_bytes(
                            "0x01432126ac23c7028200e443169c2286f99cdb5a7bf22e607bcd724efa059040",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05f750dc13ed239fa6fc43ff6e10ae9125a33bd05ec034fc3bb4dd168df3505f",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                ],
            ),
        ];

        let block_1 = vec![
            (
                str_to_felt_bytes(
                    "0x06538fdd3aa353af8a87f5fe77d1f533ea82815076e30a86d65b72d3eb4f0b80",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x000000000000000000000000000000000000000000000000000000000000022b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x01aed933fd362faecd8ea54ee749092bd21f89901b7d1872312584ac5b636c6d",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x010212fa2be788e5d943714d6a9eac5e07d8b4b48ead96b8d0a0cbe7a6dc3832",
                        ),
                        str_to_felt_bytes(
                            "0x008a81230a7e3ffa40abe541786a9b69fbb601434cec9536d5d5b2ee4df90383",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00ffda4b5cf0dce9bc9b0d035210590c73375fdbb70cd94ec6949378bffc410c",
                        ),
                        str_to_felt_bytes(
                            "0x02b36318931915f71777f7e59246ecab3189db48408952cefda72f4b7977be51",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00ffda4b5cf0dce9bc9b0d035210590c73375fdbb70cd94ec6949378bffc410d",
                        ),
                        str_to_felt_bytes(
                            "0x07e928dcf189b05e4a3dae0bc2cb98e447f1843f7debbbf574151eb67cda8797",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x0327d34747122d7a40f4670265b098757270a449ec80c4871450fffdab7c2fa8",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000065",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x01aed933fd362faecd8ea54ee749092bd21f89901b7d1872312584ac5b636c6d",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x04184fa5a6d40f47a127b046ed6facfa3e6bc3437b393da65cc74afe47ca6c6e",
                        ),
                        str_to_felt_bytes(
                            "0x001ef78e458502cd457745885204a4ae89f3880ec24db2d8ca97979dce15fedc",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05591c8c3c8d154a30869b463421cd5933770a0241e1a6e8ebcbd91bdd69bec4",
                        ),
                        str_to_felt_bytes(
                            "0x026b5943d4a0c420607cee8030a8cdd859bf2814a06633d165820960a42c6aed",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05591c8c3c8d154a30869b463421cd5933770a0241e1a6e8ebcbd91bdd69bec5",
                        ),
                        str_to_felt_bytes(
                            "0x01518eec76afd5397cefd14eda48d01ad59981f9ce9e70c233ca67acd8754008",
                        ),
                    ),
                ],
            ),
        ];

        let block_2 = vec![
            (
                str_to_felt_bytes(
                    "0x001fb4457f3fe8a976bdb9c04dd21549beeeb87d3867b10effe0c4bd4064a8e4",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x056c060e7902b3d4ec5a327f1c6e083497e586937db00af37fe803025955678f",
                    ),
                    str_to_felt_bytes(
                        "0x075495b43f53bd4b9c9179db113626af7b335be5744d68c6552e3d36a16a747c",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x05790719f16afe1450b67a92461db7d0e36298d6a5f8bab4f7fd282050e02f4f",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x0772c29fae85f8321bb38c9c3f6edb0957379abedc75c17f32bcef4e9657911a",
                    ),
                    str_to_felt_bytes(
                        "0x06d4ca0f72b553f5338a95625782a939a49b98f82f449c20f49b42ec60ed891c",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x057b973bf2eb26ebb28af5d6184b4a044b24a8dcbf724feb95782c4d1aef1ca9",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x04f2c206f3f2f1380beeb9fe4302900701e1cb48b9b33cbe1a84a175d7ce8b50",
                    ),
                    str_to_felt_bytes(
                        "0x02a614ae71faa2bcdacc5fd66965429c57c4520e38ebc6344f7cf2e78b21bd2f",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x02d6c9569dea5f18628f1ef7c15978ee3093d2d3eec3b893aac08004e678ead3",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x07f93985c1baa5bd9b2200dd2151821bd90abb87186d0be295d7d4b9bc8ca41f",
                    ),
                    str_to_felt_bytes(
                        "0x0127cd00a078199381403a33d315061123ce246c8e5f19aa7f66391a9d3bf7c6",
                    ),
                )],
            ),
        ];

        let blocks = block_0.iter().chain(block_1.iter()).chain(block_2.iter());

        // Inserts all storage updates into the bonsai
        for (contract_address, storage) in blocks.clone() {
            log::info!(
                "contract address (write): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );
            assert!(bonsai.init_tree(contract_address).is_ok());

            for (k, v) in storage {
                // truncate only keeps the first 251 bits in a key
                // so there should be no error during insertion
                let ktrunc = &truncate(k);
                let kfelt0 = Felt::from_bytes_be_slice(k);
                let kfelt1 = Felt::from_bytes_be_slice(ktrunc.as_raw_slice());

                // quick sanity check to make sure truncating a key does not remove any data
                assert_eq!(kfelt0, kfelt1);

                let v = &Felt::from_bytes_be_slice(v);
                assert!(bonsai.insert(contract_address, ktrunc, v).is_ok());
            }
        }
        assert!(bonsai.commit(BasicId::new(0)).is_ok());

        // aggreates all storage changes to their latest state
        // (replacements are takent into account)
        let mut storage_map = IndexMap::<Vec<u8>, IndexMap<Felt, Felt>>::new();
        for (contract_address, storage) in blocks.clone() {
            let map = storage_map
                .entry(contract_address.to_vec())
                .or_insert(IndexMap::new());

            for (k, v) in storage {
                let k = Felt::from_bytes_be_slice(k);
                let v = Felt::from_bytes_be_slice(v);
                map.insert(k, v);
            }
        }

        // checks for each contract if the original key can be reconstructed
        // from the data stored in the db
        for (contract_address, storage) in storage_map.iter() {
            log::info!(
                "contract address (read): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );

            let keys = bonsai.get_keys(contract_address).unwrap();
            log::debug!("{keys:?}");
            for k in keys {
                // if all has gone well, the db should contain the first 251 bits of the key,
                // which should represent the entirety of the data
                let k = Felt::from_bytes_be_slice(&k);
                log::info!("looking for key: {k:#064x}");

                assert!(storage.contains_key(&k));
            }
        }

        // makes sure retrieving key-value pairs works for each contract
        for (contract_address, storage) in storage_map.iter() {
            log::info!(
                "contract address (read): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );

            let kv = bonsai.get_key_value_pairs(contract_address).unwrap();
            log::debug!("{kv:?}");
            for (k, v) in kv {
                let k = Felt::from_bytes_be_slice(&k);
                let v = Felt::from_bytes_be_slice(&v);
                log::info!("checking for key-value pair:({k:#064x}, {v:#064x})");

                assert_eq!(*storage.get(&k).unwrap(), v);
            }
        }
    }

    fn str_to_felt_bytes(hex: &str) -> [u8; 32] {
        Felt::from_hex(hex).unwrap().to_bytes_be()
    }

    fn truncate(key: &[u8]) -> BitVec<u8, Msb0> {
        key.view_bits()[5..].to_owned()
    }
    // use crate::{
    //     databases::{create_rocks_db, RocksDB, RocksDBConfig},
    //     id::BasicId,
    //     key_value_db::KeyValueDBConfig,
    //     KeyValueDB,
    // };
    // use bitvec::vec::BitVec;
    // use mp_felt::Felt252Wrapper;
    // use mp_hashers::pedersen::PedersenHasher;
    // use parity_scale_codec::{Decode, Encode};
    // use rand::prelude::*;
    // use starknet_types_core::{felt::Felt, hash::Pedersen};

    // // convert a Madara felt to a standard Felt
    // fn felt_from_madara_felt(madara_felt: &Felt252Wrapper) -> Felt {
    //     let encoded = madara_felt.encode();
    //     Felt::decode(&mut &encoded[..]).unwrap()
    // }

    // // convert a standard Felt to a Madara felt
    // fn madara_felt_from_felt(felt: &Felt) -> Felt252Wrapper {
    //     let encoded = felt.encode();
    //     Felt252Wrapper::decode(&mut &encoded[..]).unwrap()
    // }

    // #[test]
    // fn one_commit_tree_compare() {
    //     let mut elements = vec![];
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut rng = rand::thread_rng();
    //     let tree_size = rng.gen_range(10..100);
    //     for _ in 0..tree_size {
    //         let mut element = String::from("0x");
    //         let element_size = rng.gen_range(10..32);
    //         for _ in 0..element_size {
    //             let random_byte: u8 = rng.gen();
    //             element.push_str(&format!("{:02x}", random_byte));
    //         }
    //         elements.push(Felt::from_hex(&element).unwrap());
    //     }
    //     let madara_elements = elements
    //         .iter()
    //         .map(madara_felt_from_felt)
    //         .collect::<Vec<_>>();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let root_hash = mp_commitments::calculate_class_commitment_tree_root_hash::<PedersenHasher>(
    //         &madara_elements,
    //     );
    //     elements
    //         .iter()
    //         .zip(madara_elements.iter())
    //         .for_each(|(element, madara_element)| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*madara_element);
    //             let key = &element.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });
    //     bonsai_tree.display();
    //     assert_eq!(
    //         bonsai_tree.commit().unwrap(),
    //         felt_from_madara_felt(&root_hash)
    //     );
    // }

    // #[test]
    // fn simple_commits() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt::from_hex("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 felt_from_madara_felt(&calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                     madara_felt_from_felt(class_hash),
    //                 ));
    //             madara_tree.set(
    //                 madara_felt_from_felt(class_hash),
    //                 madara_felt_from_felt(&final_hash),
    //             );
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(&BitVec::from_vec(key.to_vec()), final_hash)
    //                 .unwrap();
    //         });
    //     }
    //     let madara_root_hash = madara_tree.commit();
    //     let bonsai_root_hash = bonsai_tree.commit().unwrap();
    //     assert_eq!(bonsai_root_hash, felt_from_madara_felt(&madara_root_hash));
    // }

    // #[test]
    // fn simple_commits_and_delete() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt::from_hex("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash = calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                 madara_felt_from_felt(class_hash),
    //             );
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(&BitVec::from_vec(key.to_vec()), Felt::ZERO)
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    // }

    // #[test]
    // fn multiple_commits_tree_compare() {
    //     let mut rng = rand::thread_rng();
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let nb_commits = rng.gen_range(2..4);
    //     for _ in 0..nb_commits {
    //         let mut elements = vec![];
    //         let tree_size = rng.gen_range(10..100);
    //         for _ in 0..tree_size {
    //             let mut element = String::from("0x");
    //             let element_size = rng.gen_range(10..32);
    //             for _ in 0..element_size {
    //                 let random_byte: u8 = rng.gen();
    //                 element.push_str(&format!("{:02x}", random_byte));
    //             }
    //             elements.push(Felt::from_hex(&element).unwrap());
    //         }
    //         elements.iter().for_each(|class_hash| {
    //             let final_hash = calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                 madara_felt_from_felt(class_hash),
    //             );
    //             madara_tree.set(madara_felt_from_felt(class_hash), final_hash);
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });

    //         let bonsai_root_hash = bonsai_tree.commit().unwrap();
    //         let madara_root_hash = madara_tree.commit();
    //         assert_eq!(bonsai_root_hash, felt_from_madara_felt(&madara_root_hash));
    //     }
    // }

    // #[test]    // fn multiple_commits_tree_compare_with_deletes() {
    //     let mut rng = rand::thread_rng();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new("test_db")).unwrap();
    //     let mut db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let mut bonsai_tree: super::MerkleTree<PedersenHasher, RocksDB> =
    //         super::MerkleTree::empty(&mut db);
    //     let nb_commits = rng.gen_range(2..5);
    //     let mut elements_to_delete = vec![];
    //     for _ in 0..nb_commits {
    //         let mut elements = vec![];
    //         let tree_size = rng.gen_range(10..100);
    //         for _ in 0..tree_size {
    //             let mut element = String::from("0x");
    //             let element_size = rng.gen_range(10..32);
    //             for _ in 0..element_size {
    //                 let random_byte: u8 = rng.gen();
    //                 element.push_str(&format!("{:02x}", random_byte));
    //             }
    //             if rng.gen_bool(0.1) {
    //                 elements_to_delete.push(Felt::from_hex_be(&element).unwrap());
    //                 elements.push(Felt::from_hex_be(&element).unwrap());
    //             } else {
    //                 elements.push(Felt::from_hex_be(&element).unwrap());
    //             }
    //         }
    //         elements.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             madara_tree.set(*class_hash, final_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             bonsai_tree.set(&BitVec::from_vec(key.to_vec()), final_hash);
    //         });

    //         let bonsai_root_hash = bonsai_tree.commit();
    //         let madara_root_hash = madara_tree.commit();
    //         assert_eq!(bonsai_root_hash, madara_root_hash);
    //     }
    //     elements_to_delete.iter().for_each(|class_hash| {
    //         madara_tree.set(*class_hash, Felt::ZERO);
    //         let key = &class_hash.0.to_bytes_be()[..31];
    //         bonsai_tree.set(&BitVec::from_vec(key.to_vec()), Felt::ZERO);
    //     });

    //     let bonsai_root_hash = bonsai_tree.commit();
    //     let madara_root_hash = madara_tree.commit();
    //     assert_eq!(bonsai_root_hash, madara_root_hash);
    // }

    // #[test]
    // fn test_proof() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt252Wrapper::from_hex_be("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     Felt::from_bytes_be(&final_hash.0.to_bytes_be()),
    //                 )
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    //     let bonsai_proof = bonsai_tree
    //         .get_proof(&BitVec::from_vec(
    //             elements[0][0].0.to_bytes_be()[..31].to_vec(),
    //         ))
    //         .unwrap();
    //     println!("bonsai_proof: {:?}", bonsai_proof);
    // }

    // test in madara
    //     #[test]
    // fn test_proof() {
    //     let mut tree = super::merkle_patricia_tree::merkle_tree::MerkleTree::<PedersenHasher>::empty();
    //     let elements = [
    //         [Felt252Wrapper::from_hex_be("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             tree
    //                 .set(&BitVec::from_vec(key.to_vec()), final_hash)
    //         });
    //     }
    //     tree.commit();
    //     let bonsai_proof = tree.get_proof(&BitVec::from_vec(
    //         elements[0][0].0.to_bytes_be()[..31].to_vec(),
    //     ));
    //     println!("bonsai_proof: {:?}", bonsai_proof);
    // }
}
