use bitvec::{
    prelude::{BitSlice, BitVec, Msb0},
    view::BitView,
};
use core::marker::PhantomData;
use core::{iter, mem};
use derive_more::Constructor;
use parity_scale_codec::Decode;
#[cfg(feature = "std")]
use rayon::prelude::*;
use starknet_types_core::{felt::Felt, hash::StarkHash};

use crate::{
    error::BonsaiStorageError, format, hash_map, id::Id, vec, BonsaiDatabase, ByteVec, EncodeExt,
    HashMap, KeyValueDB, ToString, Vec,
};

use super::{
    merkle_node::{BinaryNode, Direction, EdgeNode, Node, NodeHandle, NodeId},
    path::Path,
    trie_db::TrieKeyType,
    TrieKey,
};

#[cfg(test)]
use log::trace;

#[derive(Debug, PartialEq, Eq)]
pub enum Membership {
    Member,
    NonMember,
}

/// Wrapper type for a [HashMap<NodeId, Node>] object. (It's not really a wrapper it's a
/// copy of the type but we implement the necessary traits.)
#[derive(Clone, Debug, PartialEq, Eq, Default, Constructor)]
pub struct NodesMapping(HashMap<NodeId, Node>);

/// A node used in proof generated by the trie.
///
/// See pathfinders merkle-tree crate for more information.
#[derive(Debug, Clone, PartialEq)]
pub enum ProofNode {
    Binary { left: Felt, right: Felt },
    Edge { child: Felt, path: Path },
}

impl ProofNode {
    pub fn hash<H: StarkHash>(&self) -> Felt {
        match self {
            ProofNode::Binary { left, right } => H::hash(left, right),
            ProofNode::Edge { child, path } => {
                let mut bytes = [0u8; 32];
                bytes.view_bits_mut::<Msb0>()[256 - path.0.len()..].copy_from_bitslice(&path.0);
                // SAFETY: path len is <= 251
                let path_hash = Felt::from_bytes_be(&bytes);

                let length = Felt::from(path.0.len() as u8);
                H::hash(child, &path_hash) + length
            }
        }
    }
}

#[derive(Debug)]
enum RootHandle {
    Empty,
    Loaded(NodeId),
}

pub(crate) struct MerkleTrees<H: StarkHash + Send + Sync, DB: BonsaiDatabase, CommitID: Id> {
    pub db: KeyValueDB<DB, CommitID>,
    pub trees: HashMap<ByteVec, MerkleTree<H>>,
}

#[cfg(feature = "bench")]
impl<H: StarkHash + Send + Sync, DB: BonsaiDatabase + Clone, CommitID: Id> Clone
    for MerkleTrees<H, DB, CommitID>
{
    fn clone(&self) -> Self {
        Self {
            db: self.db.clone(),
            trees: self.trees.clone(),
        }
    }
}

impl<H: StarkHash + Send + Sync, DB: BonsaiDatabase, CommitID: Id> MerkleTrees<H, DB, CommitID> {
    pub(crate) fn new(db: KeyValueDB<DB, CommitID>) -> Self {
        Self {
            db,
            trees: HashMap::new(),
        }
    }

    pub(crate) fn init_tree(
        &mut self,
        identifier: &[u8],
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let tree = MerkleTree::new(identifier.into());
        self.trees.insert(identifier.into(), tree);
        Ok(())
    }

    pub(crate) fn multi_set(
        &mut self,
        updates: impl ParallelIterator<
            Item = (
                Vec<u8>,
                impl ParallelIterator<Item = (BitVec<u8, Msb0>, Felt)>,
            ),
        >,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>>
    where
        DB: Send + Sync,
        CommitID: Send + Sync,
        H: Send + Sync,
    {
        // double try_fold try_reduce combo yay
        // this is based on MerkleTree merging, which isn't ideal --

        let merge_trees = |a: &mut HashMap<Vec<u8>, MerkleTree<H>>,
                           b: Box<HashMap<Vec<u8>, MerkleTree<H>>>|
         -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
            for (k, v) in b.into_iter() {
                match a.entry(k) {
                    hash_map::Entry::Occupied(mut entry) => {
                        entry.get_mut().merge::<DB>(v)?;
                    }
                    hash_map::Entry::Vacant(entry) => {
                        entry.insert(v);
                    }
                }
            }
            Ok(())
        };

        let _res: Option<Box<hash_map::HashMap<Vec<u8>, MerkleTree<H>>>> = updates
            .try_fold(
                || Box::new(HashMap::<Vec<u8>, MerkleTree<H>>::new()),
                |mut tries, (identifier, tree_updates)| {
                    let identifier = &identifier[..];
                    let tree = tree_updates
                        .try_fold(
                            || Box::new(MerkleTree::new(identifier.into())),
                            |mut tree, (key, value)| {
                                tree.set(&self.db, &key, value)?;
                                Ok::<_, BonsaiStorageError<DB::DatabaseError>>(tree)
                            },
                        )
                        .try_reduce_with(|mut a, b| {
                            a.merge::<DB>(*b);
                            Ok(a)
                        })
                        .transpose()?;

                    if let Some(tree) = tree {
                        tries.insert(identifier.into(), *tree);
                    }
                    Ok::<_, BonsaiStorageError<DB::DatabaseError>>(tries)
                },
            )
            .try_reduce_with(|mut a, b| {
                merge_trees(&mut a, b);
                Ok(a)
            })
            .transpose()?;

        todo!()
    }

    pub(crate) fn set(
        &mut self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
        value: Felt,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get_mut(identifier); // todo entry
        if let Some(tree) = tree {
            tree.set(&mut self.db, key, value)
        } else {
            let mut tree = MerkleTree::new(identifier.into());
            tree.set(&mut self.db, key, value)?;
            self.trees.insert(identifier.into(), tree);
            Ok(())
        }
    }

    pub(crate) fn get(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.get(&self.db, key)
        } else {
            Ok(None)
        }
    }

    pub(crate) fn get_at(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
        id: CommitID,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.get_at(&self.db, key, id)
        } else {
            Ok(None)
        }
    }

    pub(crate) fn contains(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<bool, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.contains(&self.db, key)
        } else {
            Ok(false)
        }
    }

    pub(crate) fn db_mut(&mut self) -> &mut KeyValueDB<DB, CommitID> {
        &mut self.db
    }

    pub(crate) fn reset_to_last_commit(
        &mut self,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        for tree in self.trees.values_mut() {
            tree.reset_to_last_commit::<DB>();
        }
        Ok(())
    }

    pub(crate) fn db_ref(&self) -> &KeyValueDB<DB, CommitID> {
        &self.db
    }

    pub(crate) fn root_hash(
        &self,
        identifier: &[u8],
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            Ok(tree.root_hash(&self.db)?)
        } else {
            Err(BonsaiStorageError::Trie("Tree not found".to_string()))
        }
    }

    pub(crate) fn get_keys(
        &self,
        identifier: &[u8],
    ) -> Result<Vec<Vec<u8>>, BonsaiStorageError<DB::DatabaseError>> {
        self.db
            .db
            .get_by_prefix(&crate::DatabaseKey::Flat(identifier))
            .map(|key_value_pairs| {
                // Remove the identifier from the key
                key_value_pairs
                    .into_iter()
                    // FIXME: this does not filter out keys values correctly for `HashMapDb` due
                    // to branches and leafs not being differenciated
                    .filter_map(|(key, _value)| {
                        if key.len() > identifier.len() {
                            Some(key[identifier.len() + 1..].into())
                        } else {
                            None
                        }
                    })
                    .collect()
            })
            .map_err(|e| e.into())
    }

    #[allow(clippy::type_complexity)]
    pub(crate) fn get_key_value_pairs(
        &self,
        identifier: &[u8],
    ) -> Result<Vec<(Vec<u8>, Vec<u8>)>, BonsaiStorageError<DB::DatabaseError>> {
        self.db
            .db
            .get_by_prefix(&crate::DatabaseKey::Flat(identifier))
            .map(|key_value_pairs| {
                key_value_pairs
                    .into_iter()
                    // FIXME: this does not filter out keys values correctly for `HashMapDb` due
                    // to branches and leafs not being differenciated
                    .filter_map(|(key, value)| {
                        if key.len() > identifier.len() {
                            Some((key[identifier.len() + 1..].into(), value.into_vec()))
                        } else {
                            None
                        }
                    })
                    .collect()
            })
            .map_err(|e| e.into())
    }

    pub(crate) fn commit(&mut self) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        #[cfg(not(feature = "std"))]
        let db_changes = self
            .trees
            .iter_mut()
            .map(|(_, tree)| tree.get_updates::<DB>());
        #[cfg(feature = "std")]
        let db_changes = self
            .trees
            .par_iter_mut()
            .map(|(_, tree)| tree.get_updates::<DB>())
            .collect_vec_list()
            .into_iter()
            .flatten();

        let mut batch = self.db.create_batch();
        for changes in db_changes {
            for (key, value) in changes? {
                match value {
                    InsertOrRemove::Insert(value) => {
                        self.db.insert(&key, &value, Some(&mut batch))?;
                    }
                    InsertOrRemove::Remove => {
                        self.db.remove(&key, Some(&mut batch))?;
                    }
                }
            }
        }
        self.db.write_batch(batch)?;
        Ok(())
    }

    pub(crate) fn get_proof(
        &self,
        identifier: &[u8],
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<ProofNode>, BonsaiStorageError<DB::DatabaseError>> {
        let tree = self.trees.get(identifier);
        if let Some(tree) = tree {
            tree.get_proof(&self.db, key)
        } else {
            Err(BonsaiStorageError::Trie("Tree not found".to_string()))
        }
    }

    pub(crate) fn get_identifiers(&self) -> Vec<Vec<u8>> {
        self.trees.keys().cloned().map(ByteVec::into_vec).collect()
    }
}

/// A Starknet binary Merkle-Patricia tree with a specific root entry-point and storage.
///
/// This is used to update, mutate and access global Starknet state as well as individual contract
/// states.
///
/// For more information on how this functions internally, see [here](super::merkle_node).
pub struct MerkleTree<H: StarkHash> {
    /// The handle to the current root node could be hash if no modifications has been done
    /// since the last commit or in memory if there are some modifications.
    // root_handle: NodeHandle,
    /// The last known root hash. Updated only each commit. (possibly outdated between two commits)
    // root_hash: Felt,

    /// The root node. None means the node has not been loaded yet.
    root_node: Option<RootHandle>,
    /// Identifier of the tree in the database.
    identifier: ByteVec,
    /// This storage is used to avoid modifying the underlying database each time during a commit.
    storage_nodes: NodesMapping,
    /// The id of the last node that has been added to the temporary storage.
    latest_node_id: NodeId,
    /// The list of nodes that should be removed from the underlying database during the next commit.
    death_row: Vec<TrieKey>,
    /// The list of leaves that have been modified during the current commit.
    cache_leaf_modified: HashMap<ByteVec, InsertOrRemove<Felt>>,
    /// The hasher used to hash the nodes.
    _hasher: PhantomData<H>,
}

// NB: #[derive(Clone)] does not work because it expands to an impl block which forces H: Clone, which Pedersen/Poseidon aren't.
#[cfg(feature = "bench")]
impl<H: StarkHash> Clone for MerkleTree<H> {
    fn clone(&self) -> Self {
        Self {
            root_handle: self.root_handle.clone(),
            root_hash: self.root_hash.clone(),
            identifier: self.identifier.clone(),
            storage_nodes: self.storage_nodes.clone(),
            latest_node_id: self.latest_node_id.clone(),
            death_row: self.death_row.clone(),
            cache_leaf_modified: self.cache_leaf_modified.clone(),
            _hasher: PhantomData,
        }
    }
}

#[derive(Clone, Debug, PartialEq, Eq)]
pub(crate) enum InsertOrRemove<T> {
    Insert(T),
    Remove,
}
enum NodeOrFelt<'a> {
    Node(&'a Node),
    Felt(Felt),
}

impl<H: StarkHash + Send + Sync> MerkleTree<H> {
    pub fn new(identifier: ByteVec) -> Self {
        let nodes_mapping: HashMap<NodeId, Node> = HashMap::new();
        Self {
            // root_handle: NodeHandle::Hash(root),
            // root_hash: root,
            root_node: None,
            identifier,
            storage_nodes: NodesMapping(nodes_mapping),
            latest_node_id: NodeId(0),
            death_row: Vec::new(),
            cache_leaf_modified: HashMap::new(),
            _hasher: PhantomData,
        }
    }

    // fn merge<DB: BonsaiDatabase>(
    //     &mut self,
    //     mut other: MerkleTree<H>,
    // ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
    //     fn copy_handle<DB: BonsaiDatabase>(
    //         a_map: &mut NodesMapping,
    //         a_next_id: &mut NodeId,
    //         b_map: &mut NodesMapping,
    //         handle: NodeHandle
    //     ) -> Result<NodeHandle, BonsaiStorageError<DB::DatabaseError>> {
    //         let id = a_next_id.next_id();

    //         match handle {
    //             NodeHandle::Hash(felt) => Ok(NodeHandle::Hash(felt)),
    //             NodeHandle::InMemory(b_subtree) => copy_subtree::<DB>(a_map, a_next_id, b_map, id, b_subtree),
    //         }
    //     }

    //     fn copy_subtree<DB: BonsaiDatabase>(
    //         a_map: &mut NodesMapping,
    //         a_next_id: &mut NodeId,
    //         b_map: &mut NodesMapping,
    //         a_id: NodeId,
    //         b_subtree: NodeId,
    //     ) -> Result<NodeHandle, BonsaiStorageError<DB::DatabaseError>> {
    //         let b = b_map.0.remove(&b_subtree).ok_or_else(|| BonsaiStorageError::Trie("node id has no associated node in storage".into()))?;

    //         let new_node = match b {
    //             Node::Binary(b) => {
    //                 let left = copy_handle::<DB>(a_map, a_next_id, b_map, b.left)?;
    //                 let right = copy_handle::<DB>(a_map, a_next_id, b_map, b.right)?;
    //                 Node::Binary(BinaryNode { hash: None, height: 0, left, right })
    //             },
    //             Node::Edge(b) => {
    //                 let child = copy_handle::<DB>(a_map, a_next_id, b_map, b.child)?;
    //                 Node::Edge(EdgeNode { hash: None, height: 0, path: b.path, child: child })
    //             },
    //         };

    //         a_map.0.insert(a_id, new_node);

    //         Ok(NodeHandle::InMemory(a_id))
    //     }

    //     struct PendingSubtreeCopy { a_id: NodeId, b_subtree: NodeId }

    //     // Returns Some if we need to recurse
    //     fn merge_handles<DB: BonsaiDatabase>(
    //         a: &mut NodeHandle,
    //         a_next_id: &mut NodeId,
    //         b: NodeHandle,
    //         pending_copy: &mut Vec<PendingSubtreeCopy>,
    //     ) -> Result<Option<(NodeId, NodeId)>, BonsaiStorageError<DB::DatabaseError>> {
    //         match (a, b) {
    //             (_, NodeHandle::Hash(_)) => Ok(None),
    //             (a @ NodeHandle::Hash(_), NodeHandle::InMemory(b_subtree)) => {
    //                 let a_id = a_next_id.next_id();
    //                 *a = NodeHandle::InMemory(a_id);

    //                 pending_copy.push(PendingSubtreeCopy { a_id, b_subtree });

    //                 Ok(None)
    //             }
    //             (NodeHandle::InMemory(a), NodeHandle::InMemory(b)) => Ok(Some((*a, b))),
    //         }
    //     }

    //     fn merge_nodeid<DB: BonsaiDatabase>(
    //         nodeid_a: NodeId,
    //         a_map: &mut NodesMapping,
    //         a_next_id: &mut NodeId,
    //         nodeid_b: NodeId,
    //         b_map: &mut NodesMapping,
    //         pending_copy: &mut Vec<PendingSubtreeCopy>,
    //         pending_insertion: &mut Vec<(NodeId, Node)>,
    //     ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
    //         let a = a_map.0.get_mut(&nodeid_a).ok_or_else(|| {
    //             BonsaiStorageError::Trie("node id has no associated node in storage".into())
    //         })?;
    //         let b = match b_map.0.entry(nodeid_b) {
    //             hash_map::Entry::Occupied(entry) => entry,
    //             hash_map::Entry::Vacant(_) => return Err(BonsaiStorageError::Trie("node id has no associated node in storage".into())),
    //         };

    //         let (node_id_next_1, node_id_next_2, remove_b) = match (a, b.get_mut()) {
    //             // Binary and binary: go down both arms
    //             (Node::Binary(a), Node::Binary(b)) => (
    //                 merge_handles::<DB>(&mut a.left, a_next_id, b.left, pending_copy)?,
    //                 merge_handles::<DB>(&mut a.right, a_next_id, b.right, pending_copy)?,
    //                 true
    //             ),

    //             // Binary and edge
    //             (Node::Binary(a), Node::Edge(b)) => {
    //                 // remove leading bit
    //                 let removed_bit = *b.path.0.get(0).ok_or_else(|| {
    //                     BonsaiStorageError::Trie("storage has an edge with an empty path".into())
    //                 })?;

    //                 b.path.0.drain(0..1);

    //                 // merge the binary node child with the edge
    //                 let a = a.get_child_mut(Direction::from(removed_bit));
    //                 let (b, remove_b) = if b.path.0.is_empty() {
    //                     // use child instead
    //                     (b.child, true)
    //                 } else {
    //                     (NodeHandle::InMemory(nodeid_b), false)
    //                 };

    //                 (merge_handles::<DB>(a, a_next_id, b, pending_copy)?, None, remove_b)
    //             }

    //             // Edge and binary
    //             (a @ Node::Edge(EdgeNode { path, child, .. }), Node::Binary(b)) => {
    //                 // Replace edge by a binary

    //                 let mut path = mem::take(path);
    //                 let removed_bit = *path.0.get(0).ok_or_else(|| {
    //                     BonsaiStorageError::Trie("storage has an edge with an empty path".into())
    //                 })?;
    //                 path.0.drain(0..1);
    //                 let child = child.clone();

    //                 let a_child = if path.0.is_empty() {
    //                     // use child instead
    //                     child
    //                 } else {
    //                     pending_insertion.push((a_next_id.next_id(), Node::Edge(EdgeNode { hash: None, height: 0, path, child })));

    //                     NodeHandle::InMemory(nodeid_a)
    //                 };

    //                 let (left, right) = match Direction::from(removed_bit) {
    //                     Direction::Left => {
    //                         // left: this means next turn we'll be merging the edge with the left path, and the right path is a subtree copy
    //                         let a_id = a_next_id.next_id();
    //                         pending_copy.push(PendingSubtreeCopy { a_id, b_subtree: b.right });
    //                         (a_id, a_child)
    //                     },
    //                     Direction::Right => {
    //                         // opposite
    //                         let a_id = a_next_id.next_id();
    //                         pending_copy.push(PendingSubtreeCopy { a_id, b_subtree: b.left });
    //                         (a_child, a_id)
    //                     },
    //                 };
    //                 merge_handles::<DB>(&mut a.left, a_next_id, b.left, pending_copy)?,
    //                 merge_handles::<DB>(&mut a.right, a_next_id, b.right, pending_copy)?,

    //                 // merge the new edge on the

    //                 *a = Node::Binary(BinaryNode {
    //                     hash: None,
    //                     height: 0,
    //                     left: b.left, // todo copy left
    //                     right: b.right, // todo copy rught
    //                 });

    //                 (merge_handles::<DB>(a_child, a_next_id, b_child, pending_copy)?, None, true)
    //             },

    //             // Edge edge
    //             (Node::Edge(a), Node::Edge(b)) => {
    //                 // find the matching prefix
    //                 let common = a.common_path(&b.path.0);

    //                 let a_suffix = a.path.0.split_off(common.len());
    //                 let b_suffix = b.path.0.split_off(common.len());

    //                 todo!();
    //             },
    //         };

    //         if remove_b {
    //             b.remove();
    //         }

    //         a_map.0.extend(pending_insertion.drain(..));
    //         for PendingSubtreeCopy { a_id, b_subtree } in pending_copy.drain(..) {
    //             copy_subtree(a_map, a_next_id, b_map, a_id, b_subtree)?;
    //         }

    //         if let Some((a, b)) = node_id_next_1 {
    //             merge_nodeid::<DB>(a, a_map, a_next_id, b, b_map, pending_copy, pending_insertion)?;
    //         }
    //         if let Some((a, b)) = node_id_next_2 {
    //             merge_nodeid::<DB>(a, a_map, a_next_id, b, b_map, pending_copy, pending_insertion)?;
    //         }

    //         Ok(())
    //     }

    //     match (&mut self.root_node, other.root_node) {
    //         (a @ None, b) => {
    //             *a = b;
    //         }
    //         (Some(_), None) => {}
    //         (Some(a), Some(b)) => match (a, b) {
    //             (a @ RootHandle::Empty, b) => *a = b, // todo we need to reallocate all node handles here
    //             (RootHandle::Loaded(_), RootHandle::Empty) => {}
    //             (RootHandle::Loaded(a), RootHandle::Loaded(b)) => {
    //                 merge_nodeid::<DB>(*a, &mut self.storage_nodes, &mut self.latest_node_id, b, &mut other.storage_nodes, &mut vec![])?;
    //             }
    //         },
    //     }

    //     assert_eq!(other.storage_nodes.0.len(), 0);

    //     Ok(())
    // }

    // TODO: this does not accept &mut self because borrow splitting
    // this needs to be moved into the nodes_storage api entirely and latest_node_id there too
    fn load_db_node<'a, DB: BonsaiDatabase, ID: Id>(
        storage_nodes: &'a mut NodesMapping,
        latest_node_id: &mut NodeId,
        db: &KeyValueDB<DB, ID>,
        key: &TrieKey,
    ) -> Result<Option<(NodeId, &'a mut Node)>, BonsaiStorageError<DB::DatabaseError>> {
        let node = db.get(key)?;
        let Some(node) = node else { return Ok(None) };

        let node = Node::decode(&mut node.as_slice())?;
        latest_node_id.next_id();
        let node_id = *latest_node_id;
        // Insert and return reference at the same time. Entry occupied case should not be possible.
        match storage_nodes.0.entry(node_id) {
            hash_map::Entry::Occupied(_) => Err(BonsaiStorageError::Trie(
                "duplicate node id in storage".to_string(),
            )),
            hash_map::Entry::Vacant(entry) => Ok(Some((node_id, entry.insert(node)))),
        }
    }

    /// Loads the root node or returns None if the tree is empty.
    fn get_root_node<'a, DB: BonsaiDatabase, ID: Id>(
        root_node: &mut Option<RootHandle>,
        storage_nodes: &'a mut NodesMapping,
        latest_node_id: &mut NodeId,
        identifier: &[u8],
        db: &KeyValueDB<DB, ID>,
    ) -> Result<Option<(NodeId, &'a mut Node)>, BonsaiStorageError<DB::DatabaseError>> {
        match root_node {
            Some(RootHandle::Loaded(id)) => {
                let node = storage_nodes
                    .0
                    .get_mut(&*id)
                    .ok_or(BonsaiStorageError::Trie(
                        "root node doesn't exist in the storage".to_string(),
                    ))?;
                Ok(Some((*id, node)))
            }
            Some(RootHandle::Empty) => Ok(None),
            None => {
                // load the node
                let node = Self::load_db_node(
                    storage_nodes,
                    latest_node_id,
                    db,
                    &TrieKey::new(identifier, TrieKeyType::Trie, &[]),
                )?;

                match node {
                    Some((id, n)) => {
                        *root_node = Some(RootHandle::Loaded(id));
                        Ok(Some((id, n)))
                    }
                    None => {
                        *root_node = Some(RootHandle::Empty);
                        Ok(None)
                    }
                }
            }
        }
    }

    /// # Panics
    ///
    /// Calling this function when the tree has uncommited changes is invalid as the hashes need to be recomputed.
    pub fn root_hash<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        match self.root_node {
            Some(RootHandle::Empty) => Ok(Felt::ZERO),
            Some(RootHandle::Loaded(node_id)) => {
                let node = self.storage_nodes.0.get(&node_id).ok_or_else(|| {
                    BonsaiStorageError::Trie("could not fetch root node from storage".into())
                })?;
                node.hash().ok_or_else(|| {
                    BonsaiStorageError::Trie("the tree has uncommited changes".into())
                })
            }
            None => {
                let Some(node) =
                    Self::get_trie_branch_in_db_from_path(&self.identifier, db, &Path::default())?
                else {
                    return Ok(Felt::ZERO);
                };
                // UNWRAP: the node has just been fetched
                Ok(node.hash().unwrap())
            }
        }
    }

    pub fn cache_leaf_modified(&self) -> &HashMap<ByteVec, InsertOrRemove<Felt>> {
        &self.cache_leaf_modified
    }

    /// Remove all the modifications that have been done since the last commit.
    pub fn reset_to_last_commit<DB: BonsaiDatabase>(
        &mut self,
        // db: &mut KeyValueDB<DB, ID>,
    ) {
        // let node = self
        //     .get_trie_branch_in_db_from_path(db, &Path(BitVec::<u8, Msb0>::new()))?
        //     .ok_or(BonsaiStorageError::Trie(
        //         "root node doesn't exist in the storage".to_string(),
        //     ))?;
        // let node_hash = node.hash().ok_or(BonsaiStorageError::Trie(
        //     "Root doesn't exist in the storage".to_string(),
        // ))?;
        self.latest_node_id.reset();
        self.storage_nodes.0.clear();
        self.cache_leaf_modified.clear();
        self.root_node = None;
        // self.root_handle = NodeHandle::Hash(node_hash);
        // self.root_hash = node_hash;
    }

    /// Calculate all the new hashes and the root hash.
    #[allow(clippy::type_complexity)]
    pub(crate) fn get_updates<DB: BonsaiDatabase>(
        &mut self,
    ) -> Result<Vec<(TrieKey, InsertOrRemove<ByteVec>)>, BonsaiStorageError<DB::DatabaseError>>
    {
        let mut updates = vec![];
        for node_key in mem::take(&mut self.death_row) {
            updates.push((node_key, InsertOrRemove::Remove));
        }

        // compute hashes
        let mut hashes = vec![];
        self.compute_root_hash::<DB>(&mut hashes)?;

        // commit the tree
        match &self.root_node {
            Some(RootHandle::Loaded(node_id)) => {
                self.commit_subtree::<DB>(
                    &mut updates,
                    *node_id,
                    Path(BitVec::new()),
                    &mut hashes.drain(..),
                )?;
            }
            _ => {}
        }

        for (key, value) in mem::take(&mut self.cache_leaf_modified) {
            updates.push((
                TrieKey::new(&self.identifier, TrieKeyType::Flat, &key),
                match value {
                    InsertOrRemove::Insert(value) => {
                        InsertOrRemove::Insert(value.encode_sbytevec())
                    }
                    InsertOrRemove::Remove => InsertOrRemove::Remove,
                },
            ));
        }
        self.latest_node_id.reset();
        Ok(updates)
    }

    fn get_node_or_felt<DB: BonsaiDatabase>(
        &self,
        node_handle: &NodeHandle,
    ) -> Result<NodeOrFelt, BonsaiStorageError<DB::DatabaseError>> {
        let node_id = match node_handle {
            NodeHandle::Hash(hash) => return Ok(NodeOrFelt::Felt(*hash)),
            NodeHandle::InMemory(root_id) => root_id,
        };
        let node = self
            .storage_nodes
            .0
            .get(node_id)
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch node in the temporary storage".to_string(),
            ))?;
        Ok(NodeOrFelt::Node(node))
    }

    fn compute_root_hash<DB: BonsaiDatabase>(
        &self,
        hashes: &mut Vec<Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        let handle = match &self.root_node {
            Some(RootHandle::Loaded(node_id)) => *node_id,
            Some(RootHandle::Empty) => return Ok(Felt::ZERO),
            None => {
                return Err(BonsaiStorageError::Trie(
                    "root node is not loaded".to_string(),
                ))
            }
        };
        let Some(node) = self.storage_nodes.0.get(&handle) else {
            return Err(BonsaiStorageError::Trie(
                "could not fetch root node from storage".to_string(),
            ));
        };
        self.compute_hashes::<DB>(node, Path(BitVec::new()), hashes)
    }

    /// Compute the hashes of all of the updated nodes in the merkle tree. This step
    /// is separate from [`commit_subtree`] as it is done in parallel using rayon.
    /// Computed hashes are pushed to the `hashes` vector, depth first.
    fn compute_hashes<DB: BonsaiDatabase>(
        &self,
        node: &Node,
        path: Path,
        hashes: &mut Vec<Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        use Node::*;

        match node {
            Binary(binary) => {
                // we check if we have one or two changed children

                let left_path = path.new_with_direction(Direction::Left);
                let node_left = self.get_node_or_felt::<DB>(&binary.left)?;
                let right_path = path.new_with_direction(Direction::Right);
                let node_right = self.get_node_or_felt::<DB>(&binary.right)?;

                let (left_hash, right_hash) = match (node_left, node_right) {
                    #[cfg(feature = "std")]
                    (NodeOrFelt::Node(left), NodeOrFelt::Node(right)) => {
                        // two children: use rayon
                        let (left, right) = rayon::join(
                            || self.compute_hashes::<DB>(left, left_path, hashes),
                            || {
                                let mut hashes = vec![];
                                let felt =
                                    self.compute_hashes::<DB>(right, right_path, &mut hashes)?;
                                Ok::<_, BonsaiStorageError<DB::DatabaseError>>((felt, hashes))
                            },
                        );
                        let (left_hash, (right_hash, hashes2)) = (left?, right?);
                        hashes.extend(hashes2);

                        (left_hash, right_hash)
                    }
                    (left, right) => {
                        let left_hash = match left {
                            NodeOrFelt::Felt(felt) => felt,
                            NodeOrFelt::Node(node) => {
                                self.compute_hashes::<DB>(node, left_path, hashes)?
                            }
                        };
                        let right_hash = match right {
                            NodeOrFelt::Felt(felt) => felt,
                            NodeOrFelt::Node(node) => {
                                self.compute_hashes::<DB>(node, right_path, hashes)?
                            }
                        };
                        (left_hash, right_hash)
                    }
                };

                let hash = H::hash(&left_hash, &right_hash);
                hashes.push(hash);
                Ok(hash)
            }

            Edge(edge) => {
                let mut child_path = path.clone();
                child_path.0.extend(&edge.path.0);
                let child_hash = match self.get_node_or_felt::<DB>(&edge.child)? {
                    NodeOrFelt::Felt(felt) => felt,
                    NodeOrFelt::Node(node) => {
                        self.compute_hashes::<DB>(node, child_path, hashes)?
                    }
                };

                let mut bytes = [0u8; 32];
                bytes.view_bits_mut::<Msb0>()[256 - edge.path.0.len()..]
                    .copy_from_bitslice(&edge.path.0);

                let felt_path = Felt::from_bytes_be(&bytes);
                let mut length = [0; 32];
                // Safe as len() is guaranteed to be <= 251
                length[31] = edge.path.0.len() as u8;

                let length = Felt::from_bytes_be(&length);
                let hash = H::hash(&child_hash, &felt_path) + length;
                hashes.push(hash);
                Ok(hash)
            }
        }
    }

    /// Persists any changes in this subtree to storage.
    ///
    /// This necessitates recursively calculating the hash of, and
    /// in turn persisting, any changed child nodes. This is necessary
    /// as the parent node's hash relies on its children hashes.
    /// Hash computation is done in parallel with [`compute_hashes`] beforehand.
    ///
    /// In effect, the entire tree gets persisted.
    ///
    /// # Arguments
    ///
    /// * `node_handle` - The top node from the subtree to commit.
    /// * `hashes` - The precomputed hashes for the subtree as returned by [`compute_hashes`].
    ///   The order is depth first, left to right.
    ///
    /// # Panics
    ///
    /// Panics if the precomputed `hashes` do not match the length of the modified subtree.
    fn commit_subtree<DB: BonsaiDatabase>(
        &mut self,
        updates: &mut Vec<(TrieKey, InsertOrRemove<ByteVec>)>,
        node_id: NodeId,
        path: Path,
        hashes: &mut impl Iterator<Item = Felt>,
    ) -> Result<Felt, BonsaiStorageError<DB::DatabaseError>> {
        match self
            .storage_nodes
            .0
            .remove(&node_id)
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch node in the temporary storage".to_string(),
            ))? {
            Node::Binary(mut binary) => {
                let left_path = path.new_with_direction(Direction::Left);
                let left_hash = match binary.left {
                    NodeHandle::Hash(left_hash) => left_hash,
                    NodeHandle::InMemory(node_id) => {
                        self.commit_subtree::<DB>(updates, node_id, left_path, hashes)?
                    }
                };
                let right_path = path.new_with_direction(Direction::Right);
                let right_hash = match binary.right {
                    NodeHandle::Hash(right_hash) => right_hash,
                    NodeHandle::InMemory(node_id) => {
                        self.commit_subtree::<DB>(updates, node_id, right_path, hashes)?
                    }
                };

                let hash = hashes.next().expect("mismatched hash state");

                binary.hash = Some(hash);
                binary.left = NodeHandle::Hash(left_hash);
                binary.right = NodeHandle::Hash(right_hash);
                let key_bytes: ByteVec = path.into();
                updates.push((
                    TrieKey::new(&self.identifier, TrieKeyType::Trie, &key_bytes),
                    InsertOrRemove::Insert(Node::Binary(binary).encode_sbytevec()),
                ));
                Ok(hash)
            }
            Node::Edge(mut edge) => {
                let mut child_path = path.clone();
                child_path.0.extend(&edge.path.0);
                let child_hash = match edge.child {
                    NodeHandle::Hash(right_hash) => right_hash,
                    NodeHandle::InMemory(node_id) => {
                        self.commit_subtree::<DB>(updates, node_id, child_path, hashes)?
                    }
                };
                let hash = hashes.next().expect("mismatched hash state");
                edge.hash = Some(hash);
                edge.child = NodeHandle::Hash(child_hash);
                let key_bytes: ByteVec = path.into();
                updates.push((
                    TrieKey::new(&self.identifier, TrieKeyType::Trie, &key_bytes),
                    InsertOrRemove::Insert(Node::Edge(edge).encode_sbytevec()),
                ));
                Ok(hash)
            }
        }
    }

    /// Sets the value of a key. To delete a key, set the value to [Felt::ZERO].
    ///
    /// # Arguments
    ///
    /// * `key` - The key to set.
    /// * `value` - The value to set.
    pub fn set<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
        value: Felt,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        if value == Felt::ZERO {
            return self.delete_leaf(db, key);
        }
        let key_bytes = bitslice_to_bytes(key);
        if let Some(InsertOrRemove::Insert(value_db)) = self.cache_leaf_modified.get(&key_bytes) {
            if &value == value_db {
                return Ok(());
            }
        }
        if let Some(value_db) = db.get(&TrieKey::new(
            &self.identifier,
            TrieKeyType::Flat,
            &key_bytes,
        ))? {
            if value == Felt::decode(&mut value_db.as_slice()).unwrap() {
                return Ok(());
            }
        }
        let path = self.preload_nodes(db, key)?;
        // There are three possibilities.
        //
        // 1. The leaf exists, in which case we simply change its value.
        //
        // 2. The tree is empty, we insert the new leaf and the root becomes an edge node connecting to it.
        //
        // 3. The leaf does not exist, and the tree is not empty. The final node in the traversal will be an
        //    edge node who's path diverges from our new leaf node's.
        //
        //    This edge must be split into a new subtree containing both the existing edge's child and the
        //    new leaf. This requires an edge followed by a binary node and then further edges to both the
        //    current child and the new leaf. Any of these new edges may also end with an empty path in
        //    which case they should be elided. It depends on the common path length of the current edge
        //    and the new leaf i.e. the split may be at the first bit (in which case there is no leading
        //    edge), or the split may be in the middle (requires both leading and post edges), or the
        //    split may be the final bit (no post edge).
        use Node::*;
        match path.last() {
            Some(node_id) => {
                let mut nodes_to_add = Vec::new();
                self.storage_nodes.0.entry(*node_id).and_modify(|node| {
                    match node {
                        Edge(edge) => {
                            let common = edge.common_path(key);
                            // Height of the binary node
                            let branch_height = edge.height as usize + common.len();
                            if branch_height == key.len() {
                                edge.child = NodeHandle::Hash(value);
                                // The leaf already exists, we simply change its value.
                                self.cache_leaf_modified
                                    .insert(key_bytes, InsertOrRemove::Insert(value));
                                return;
                            }
                            // Height of the binary node's children
                            let child_height = branch_height + 1;

                            // Path from binary node to new leaf
                            let new_path = key[child_height..].to_bitvec();
                            // Path from binary node to existing child
                            let old_path = edge.path.0[common.len() + 1..].to_bitvec();

                            // The new leaf branch of the binary node.
                            // (this may be edge -> leaf, or just leaf depending).
                            self.cache_leaf_modified
                                .insert(key_bytes, InsertOrRemove::Insert(value));

                            let new = if new_path.is_empty() {
                                NodeHandle::Hash(value)
                            } else {
                                let new_edge = Node::Edge(EdgeNode {
                                    hash: None,
                                    height: child_height as u64,
                                    path: Path(new_path),
                                    child: NodeHandle::Hash(value),
                                });
                                let edge_id = self.latest_node_id.next_id();
                                nodes_to_add.push((edge_id, new_edge));
                                NodeHandle::InMemory(edge_id)
                            };

                            // The existing child branch of the binary node.
                            let old = if old_path.is_empty() {
                                edge.child
                            } else {
                                let old_edge = Node::Edge(EdgeNode {
                                    hash: None,
                                    height: child_height as u64,
                                    path: Path(old_path),
                                    child: edge.child,
                                });
                                let edge_id = self.latest_node_id.next_id();
                                nodes_to_add.push((edge_id, old_edge));
                                NodeHandle::InMemory(edge_id)
                            };

                            let new_direction = Direction::from(key[branch_height]);
                            let (left, right) = match new_direction {
                                Direction::Left => (new, old),
                                Direction::Right => (old, new),
                            };

                            let branch = Node::Binary(BinaryNode {
                                hash: None,
                                height: branch_height as u64,
                                left,
                                right,
                            });

                            // We may require an edge leading to the binary node.
                            let new_node = if common.is_empty() {
                                branch
                            } else {
                                let branch_id = self.latest_node_id.next_id();
                                nodes_to_add.push((branch_id, branch));

                                Node::Edge(EdgeNode {
                                    hash: None,
                                    height: edge.height,
                                    path: Path(common.to_bitvec()),
                                    child: NodeHandle::InMemory(branch_id),
                                })
                            };
                            let path = key[..edge.height as usize].to_bitvec();
                            let key_bytes = iter::once(path.len() as u8)
                                .chain(path.as_raw_slice().iter().copied())
                                .collect();
                            self.death_row.push(TrieKey::Trie(key_bytes));
                            *node = new_node;
                        }
                        Binary(binary) => {
                            if (binary.height + 1) as usize == key.len() {
                                let direction = Direction::from(key[binary.height as usize]);
                                match direction {
                                    Direction::Left => binary.left = NodeHandle::Hash(value),
                                    Direction::Right => binary.right = NodeHandle::Hash(value),
                                };
                            }
                        }
                        _ => {}
                    }
                });
                self.storage_nodes.0.extend(nodes_to_add);
                Ok(())
            }
            None => {
                // Getting no travel nodes implies that the tree is empty.
                //
                // Create a new leaf node with the value, and the root becomes
                // an edge node connecting to the leaf.
                let edge = Node::Edge(EdgeNode {
                    hash: None,
                    height: 0,
                    path: Path(key.to_bitvec()),
                    child: NodeHandle::Hash(value),
                });
                self.storage_nodes
                    .0
                    .insert(self.latest_node_id.next_id(), edge);

                self.root_node = Some(RootHandle::Loaded(self.latest_node_id));

                let key_bytes = bitslice_to_bytes(key);
                self.cache_leaf_modified
                    .insert(key_bytes, InsertOrRemove::Insert(value));
                Ok(())
            }
        }
    }

    /// Deletes a leaf node from the tree.
    ///
    /// This is not an external facing API; the functionality is instead accessed by calling
    /// [`MerkleTree::set`] with value set to [`Felt::ZERO`].
    ///
    /// # Arguments
    ///
    /// * `key` - The key to delete.
    fn delete_leaf<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        // Algorithm explanation:
        //
        // The leaf's parent node is either an edge, or a binary node.
        // If it's an edge node, then it must also be deleted. And its parent
        // must be a binary node. In either case we end up with a binary node
        // who's one child is deleted. This changes the binary to an edge node.
        //
        // Note that its possible that there is no binary node -- if the resulting tree would be empty.
        //
        // This new edge node may need to merge with the old binary node's parent node
        // and other remaining child node -- if they're also edges.
        //
        // Then we are done.
        let key_bytes = bitslice_to_bytes(key);
        if db
            .get(&TrieKey::new(
                &self.identifier,
                TrieKeyType::Flat,
                &key_bytes,
            ))?
            .is_none()
            && !self.cache_leaf_modified.contains_key(&key_bytes)
        {
            return Ok(());
        }
        self.cache_leaf_modified
            .insert(key_bytes.clone(), InsertOrRemove::Remove);

        let path = self.preload_nodes(db, key)?;

        let mut last_binary_path = Path(key.to_bitvec());

        // Go backwards until we hit a branch node.
        let mut node_iter = path.into_iter().rev().skip_while(|node| {
            // SAFETY: Has been populate by preload_nodes just above
            let node = self.storage_nodes.0.get(node).unwrap();
            match node {
                Node::Binary(_) => {}
                Node::Edge(edge) => {
                    for _ in 0..edge.path.0.len() {
                        last_binary_path.0.pop();
                    }
                    let mut new_path = Path(BitVec::new());
                    for i in last_binary_path.0.iter() {
                        new_path.0.push(*i);
                    }
                    last_binary_path = new_path;
                    let path: ByteVec = (&last_binary_path).into();
                    self.death_row
                        .push(TrieKey::new(&self.identifier, TrieKeyType::Trie, &path));
                }
            }
            !node.is_binary()
        });
        let branch_node = node_iter.next();
        let parent_branch_node = node_iter.next();
        match branch_node {
            Some(node_id) => {
                let new_edge =
                    {
                        let node = self.storage_nodes.0.get_mut(&node_id).ok_or(
                            BonsaiStorageError::Trie("Node not found in memory".to_string()),
                        )?;
                        // SAFETY: This node must be a binary node due to the iteration condition.
                        let binary = node.as_binary().unwrap();
                        let (direction, height) =
                            { (binary.direction(key).invert(), binary.height) };
                        last_binary_path.0.pop();
                        last_binary_path.0.push(bool::from(direction));
                        // Create an edge node to replace the old binary node
                        // i.e. with the remaining child (note the direction invert),
                        //      and a path of just a single bit.
                        let path =
                            Path(iter::once(bool::from(direction)).collect::<BitVec<_, _>>());
                        let mut edge = EdgeNode {
                            hash: None,
                            height,
                            path,
                            child: match direction {
                                Direction::Left => binary.left,
                                Direction::Right => binary.right,
                            },
                        };

                        // Merge the remaining child if it's an edge.
                        self.merge_edges::<DB, ID>(&mut edge, db, &last_binary_path)?;
                        edge
                    };
                // Check the parent of the new edge. If it is also an edge, then they must merge.
                if let Some(parent_node_id) = parent_branch_node {
                    // Get a mutable reference to the parent node to merge them
                    let parent_node = self.storage_nodes.0.get_mut(&parent_node_id).ok_or(
                        BonsaiStorageError::Trie("Node not found in memory".to_string()),
                    )?;
                    if let Node::Edge(parent_edge) = parent_node {
                        parent_edge.path.0.extend_from_bitslice(&new_edge.path.0);
                        parent_edge.child = new_edge.child;
                    } else {
                        self.storage_nodes.0.insert(node_id, Node::Edge(new_edge));
                    }
                } else {
                    self.storage_nodes.0.insert(node_id, Node::Edge(new_edge));
                }
            }
            None => {
                // We reached the root without a hitting binary node. The new tree
                // must therefore be empty.
                self.root_node = Some(RootHandle::Empty);
                return Ok(());
            }
        };
        Ok(())
    }

    /// Returns the value stored at key, or `None` if it does not exist.
    ///
    /// # Arguments
    ///
    /// * `key` - The key of the value to get.
    ///
    /// # Returns
    ///
    /// The value of the key.
    pub fn get<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let key = bitslice_to_bytes(key);
        if let Some(value) = self.cache_leaf_modified.get(&key) {
            match value {
                InsertOrRemove::Remove => return Ok(None),
                InsertOrRemove::Insert(value) => return Ok(Some(*value)),
            }
        }
        db.get(&TrieKey::new(&self.identifier, TrieKeyType::Flat, &key))
            .map(|r| r.map(|opt| Felt::decode(&mut opt.as_slice()).unwrap()))
    }

    pub fn get_at<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
        id: ID,
    ) -> Result<Option<Felt>, BonsaiStorageError<DB::DatabaseError>> {
        let key = bitslice_to_bytes(key);
        db.get_at(&TrieKey::new(&self.identifier, TrieKeyType::Flat, &key), id)
            .map(|r| r.map(|opt| Felt::decode(&mut opt.as_slice()).unwrap()))
    }

    pub fn contains<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<bool, BonsaiStorageError<DB::DatabaseError>> {
        let key = bitslice_to_bytes(key);
        if let Some(value) = self.cache_leaf_modified.get(&key) {
            match value {
                InsertOrRemove::Remove => return Ok(false),
                InsertOrRemove::Insert(_) => return Ok(true),
            }
        }
        db.contains(&TrieKey::new(&self.identifier, TrieKeyType::Flat, &key))
    }

    /// Returns the list of nodes along the path.
    ///
    /// if it exists, or down to the node which proves that the key does not exist.
    ///
    /// The nodes are returned in order, root first.
    ///
    /// Verification is performed by confirming that:
    ///   1. the chain follows the path of `key`, and
    ///   2. the hashes are correct, and
    ///   3. the root hash matches the known root
    ///
    /// # Arguments
    ///
    /// * `key` - The key to get the merkle proof of.
    ///
    /// # Returns
    ///
    /// The merkle proof and all the child nodes hashes.
    pub fn get_proof<DB: BonsaiDatabase, ID: Id>(
        &self,
        db: &KeyValueDB<DB, ID>,
        key: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<ProofNode>, BonsaiStorageError<DB::DatabaseError>> {
        let mut nodes = Vec::with_capacity(251);
        let mut node = match self.root_node {
            Some(RootHandle::Empty) => {
                return Ok(Vec::new());
            }
            Some(RootHandle::Loaded(node_id)) => self
                .storage_nodes
                .0
                .get(&node_id)
                .ok_or(BonsaiStorageError::Trie(
                    "Couldn't get root node from storage".to_string(),
                ))?
                .clone(),
            None => Self::get_trie_branch_in_db_from_path(
                &self.identifier,
                db,
                &Path(BitVec::<u8, Msb0>::new()),
            )?
            .ok_or(BonsaiStorageError::Trie(
                "Couldn't fetch root node in db".to_string(),
            ))?,
        };
        loop {
            match node {
                Node::Edge(edge) => {
                    let child_path = key[..edge.height as usize + edge.path.0.len()].to_bitvec();
                    let child_node = match edge.child {
                        NodeHandle::Hash(hash) => {
                            let node = Self::get_trie_branch_in_db_from_path(
                                &self.identifier,
                                db,
                                &Path(child_path),
                            )?;
                            if let Some(node) = node {
                                node
                            } else {
                                nodes.push(ProofNode::Edge {
                                    child: hash,
                                    path: edge.path.clone(),
                                });
                                return Ok(nodes);
                            }
                        }
                        NodeHandle::InMemory(child_id) => self
                            .storage_nodes
                            .0
                            .get(&child_id)
                            .ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch child node in the temporary storage".to_string(),
                            ))?
                            .clone(),
                    };
                    nodes.push(ProofNode::Edge {
                        child: child_node.hash().ok_or(BonsaiStorageError::Trie(
                            "Couldn't fetch child node in the temporary storage".to_string(),
                        ))?,
                        path: edge.path.clone(),
                    });
                    if edge.path_matches(key) {
                        node = child_node;
                    } else {
                        return Ok(nodes);
                    }
                    if edge.common_path(key) == key {
                        return Ok(nodes);
                    }
                }
                Node::Binary(binary) => {
                    let next_direction = key
                        .get(binary.height as usize)
                        .map(|b| Direction::from(*b))
                        .ok_or(BonsaiStorageError::Trie("Key too short".to_string()))?;
                    let next = binary.get_child(next_direction);
                    let next_path = key[..binary.height as usize + 1].to_bitvec();
                    let next_node = match next {
                        NodeHandle::Hash(_) => Self::get_trie_branch_in_db_from_path(
                            &self.identifier,
                            db,
                            &Path(next_path),
                        )?
                        .ok_or(BonsaiStorageError::Trie(
                            "Couldn't fetch next node in db".to_string(),
                        ))?,
                        NodeHandle::InMemory(next_id) => self
                            .storage_nodes
                            .0
                            .get(&next_id)
                            .ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch next node in the temporary storage".to_string(),
                            ))?
                            .clone(),
                    };
                    let other = binary.get_child(next_direction.invert());
                    let other_hash = match other {
                        NodeHandle::Hash(hash) => hash,
                        NodeHandle::InMemory(other_id) => {
                            let other_node = self
                                .storage_nodes
                                .0
                                .get(&other_id)
                                .ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch other node in the temporary storage"
                                        .to_string(),
                                ))?
                                .clone();
                            other_node.hash().ok_or(BonsaiStorageError::Trie(
                                "Couldn't fetch other node in the temporary storage".to_string(),
                            ))?
                        }
                    };
                    match next_direction {
                        Direction::Left => {
                            nodes.push(ProofNode::Binary {
                                left: next_node.hash().ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch next node in the temporary storage".to_string(),
                                ))?,
                                right: other_hash,
                            });
                        }
                        Direction::Right => {
                            nodes.push(ProofNode::Binary {
                                left: other_hash,
                                right: next_node.hash().ok_or(BonsaiStorageError::Trie(
                                    "Couldn't fetch next node in the temporary storage".to_string(),
                                ))?,
                            });
                        }
                    }
                    node = next_node;
                } // Node::Unresolved(hash) => {
                  //     nodes.push(ProofNode::Edge {
                  //         child: hash,
                  //         path: Path(BitVec::<u8, Msb0>::new()),
                  //     });
                  //     return Ok(nodes);
                  // }
            }
        }
    }

    /// preload_nodes from the current root towards the destination [Leaf](Node::Leaf) node.
    /// If the destination node exists, it will be the final node in the list.
    ///
    /// This means that the final node will always be either a the destination [Leaf](Node::Leaf)
    /// node, or an [Edge](Node::Edge) node who's path suffix does not match the leaf's path.
    ///
    /// The final node can __not__ be a [Binary](Node::Binary) node since it would always be
    /// possible to continue on towards the destination. Nor can it be an
    /// [Unresolved](Node::Unresolved) node since this would be resolved to check if we can
    /// travel further.
    ///
    /// # Arguments
    ///
    /// * `dst` - The node to get to.
    ///
    /// # Returns
    ///
    /// The list of nodes along the path.
    fn preload_nodes<DB: BonsaiDatabase, ID: Id>(
        &mut self,
        db: &KeyValueDB<DB, ID>,
        dst: &BitSlice<u8, Msb0>,
    ) -> Result<Vec<NodeId>, BonsaiStorageError<DB::DatabaseError>> {
        let mut nodes = Vec::with_capacity(251);
        let mut path = Path(BitVec::<u8, Msb0>::with_capacity(251));

        let mut prev_handle = None::<&mut NodeHandle>; // None signals tree root

        loop {
            // get node from cache or database
            let (node_id, node) = match prev_handle {
                // tree root
                None => {
                    match Self::get_root_node(
                        &mut self.root_node,
                        &mut self.storage_nodes,
                        &mut self.latest_node_id,
                        &self.identifier,
                        db,
                    )? {
                        Some(node) => node,
                        None => {
                            // empty tree
                            return Ok(nodes);
                        }
                    }
                }
                // not tree root
                Some(prev_handle) => match prev_handle {
                    NodeHandle::Hash(_) => {
                        // load from db
                        let Some(node) =
                            Self::get_trie_branch_in_db_from_path(&self.identifier, db, &path)?
                        else {
                            // end of path traversal
                            break;
                        };

                        // put it in inmemory storage
                        self.latest_node_id.next_id();
                        *prev_handle = NodeHandle::InMemory(self.latest_node_id);
                        let node = self.storage_nodes.0.entry(self.latest_node_id).insert(node);

                        (self.latest_node_id, node.into_mut())
                    }
                    NodeHandle::InMemory(node_id) => {
                        let node_id = *node_id;

                        let node = self.storage_nodes.0.get_mut(&node_id).ok_or(
                            BonsaiStorageError::Trie(
                                "Couldn't get node from temp storage".to_string(),
                            ),
                        )?;

                        (node_id, node)
                    }
                },
            };

            nodes.push(node_id);

            // visit the child
            match node {
                Node::Binary(binary_node) => {
                    let next_direction = binary_node.direction(dst);
                    path.0.push(bool::from(next_direction));
                    prev_handle = Some(binary_node.get_child_mut(next_direction));
                }

                Node::Edge(edge_node) if edge_node.path_matches(dst) => {
                    path.0.extend_from_bitslice(&edge_node.path.0);
                    if path.0 == dst {
                        break; // found it :)
                    }

                    prev_handle = Some(&mut edge_node.child);
                }

                // We are in a case where the edge node doesn't match the path we want to preload so we return nothing.
                Node::Edge(_) => break,
            }
        }

        Ok(nodes)
    }

    /// Get the node of the trie that corresponds to the path.
    fn get_trie_branch_in_db_from_path<DB: BonsaiDatabase, ID: Id>(
        identifier: &[u8],
        db: &KeyValueDB<DB, ID>,
        path: &Path,
    ) -> Result<Option<Node>, BonsaiStorageError<DB::DatabaseError>> {
        let path: ByteVec = path.into();
        db.get(&TrieKey::new(identifier, TrieKeyType::Trie, &path))?
            .map(|node| {
                Node::decode(&mut node.as_slice()).map_err(|err| {
                    BonsaiStorageError::Trie(format!("Couldn't decode node: {}", err))
                })
            })
            .map_or(Ok(None), |r| r.map(Some))
    }

    /// This is a convenience function which merges the edge node with its child __iff__ it is also
    /// an edge.
    ///
    /// Does nothing if the child is not also an edge node.
    ///
    /// This can occur when mutating the tree (e.g. deleting a child of a binary node), and is an
    /// illegal state (since edge nodes __must be__ maximal subtrees).
    ///
    /// # Arguments
    ///
    /// * `parent` - The parent node to merge the child with.
    fn merge_edges<DB: BonsaiDatabase, ID: Id>(
        &self,
        parent: &mut EdgeNode,
        db: &KeyValueDB<DB, ID>,
        path: &Path,
    ) -> Result<(), BonsaiStorageError<DB::DatabaseError>> {
        let child_node = match parent.child {
            NodeHandle::Hash(_) => {
                let node = Self::get_trie_branch_in_db_from_path(&self.identifier, db, path)?;
                if let Some(node) = node {
                    node
                } else {
                    return Ok(());
                }
            }
            NodeHandle::InMemory(child_id) => self
                .storage_nodes
                .0
                .get(&child_id)
                .ok_or(BonsaiStorageError::Trie(
                    "Couldn't fetch node in memory".to_string(),
                ))?
                .clone(),
        };
        if let Node::Edge(child_edge) = child_node {
            parent.path.0.extend_from_bitslice(&child_edge.path.0);
            parent.child = child_edge.child;
        }
        Ok(())
    }

    /// Function that come from pathfinder_merkle_tree::merkle_tree::MerkleTree
    /// Verifies that the key `key` with value `value` is indeed part of the MPT that has root
    /// `root`, given `proofs`.
    /// Supports proofs of non-membership as well as proof of membership: this function returns
    /// an enum corresponding to the membership of `value`, or returns `None` in case of a hash mismatch.
    /// The algorithm follows this logic:
    /// 1. init expected_hash <- root hash
    /// 2. loop over nodes: current <- nodes[i]
    ///    1. verify the current node's hash matches expected_hash (if not then we have a bad proof)
    ///    2. move towards the target - if current is:
    ///       1. binary node then choose the child that moves towards the target, else if
    ///       2. edge node then check the path against the target bits
    ///          1. If it matches then proceed with the child, else
    ///          2. if it does not match then we now have a proof that the target does not exist
    ///    3. nibble off target bits according to which child you got in (2). If all bits are gone then you
    ///       have reached the target and the child hash is the value you wanted and the proof is complete.
    ///    4. set expected_hash <- to the child hash
    /// 3. check that the expected_hash is `value` (we should've reached the leaf)
    pub fn verify_proof(
        root: Felt,
        key: &BitSlice<u8, Msb0>,
        value: Felt,
        proofs: &[ProofNode],
    ) -> Option<Membership> {
        // Protect from ill-formed keys
        if key.len() > 251 {
            return None;
        }

        let mut expected_hash = root;
        let mut remaining_path: &BitSlice<u8, Msb0> = key;

        for proof_node in proofs.iter() {
            // Hash mismatch? Return None.
            if proof_node.hash::<H>() != expected_hash {
                return None;
            }
            match proof_node {
                ProofNode::Binary { left, right } => {
                    // Direction will always correspond to the 0th index
                    // because we're removing bits on every iteration.
                    let direction = Direction::from(remaining_path[0]);

                    // Set the next hash to be the left or right hash,
                    // depending on the direction
                    expected_hash = match direction {
                        Direction::Left => *left,
                        Direction::Right => *right,
                    };

                    // Advance by a single bit
                    remaining_path = &remaining_path[1..];
                }
                ProofNode::Edge { child, path } => {
                    if path.0 != remaining_path[..path.0.len()] {
                        // If paths don't match, we've found a proof of non membership because we:
                        // 1. Correctly moved towards the target insofar as is possible, and
                        // 2. hashing all the nodes along the path does result in the root hash, which means
                        // 3. the target definitely does not exist in this tree
                        return Some(Membership::NonMember);
                    }

                    // Set the next hash to the child's hash
                    expected_hash = *child;

                    // Advance by the whole edge path
                    remaining_path = &remaining_path[path.0.len()..];
                }
            }
        }

        // At this point, we should reach `value` !
        if expected_hash == value {
            Some(Membership::Member)
        } else {
            // Hash mismatch. Return `None`.
            None
        }
    }

    #[cfg(test)]
    #[allow(dead_code)]
    fn display(&self) {
        match self.root_node {
            Some(RootHandle::Empty) => {
                trace!("tree is empty")
            }
            Some(RootHandle::Loaded(node)) => {
                trace!("root is node {:?}", node);
                self.print(&node);
            }
            None => trace!("root is not loaded"),
        }
    }

    #[cfg(test)]
    #[allow(dead_code)]
    fn print(&self, head: &NodeId) {
        use Node::*;

        let current_tmp = self.storage_nodes.0.get(head).unwrap().clone();
        trace!("bonsai_node {:?} = {:?}", head, current_tmp);

        match current_tmp {
            Binary(binary) => {
                match &binary.get_child(Direction::Left) {
                    NodeHandle::Hash(hash) => {
                        trace!("left is hash {:?}", hash);
                    }
                    NodeHandle::InMemory(left_id) => {
                        self.print(left_id);
                    }
                }
                match &binary.get_child(Direction::Right) {
                    NodeHandle::Hash(hash) => {
                        trace!("right is hash {:?}", hash);
                    }
                    NodeHandle::InMemory(right_id) => {
                        self.print(right_id);
                    }
                }
            }
            Edge(edge) => match &edge.child {
                NodeHandle::Hash(hash) => {
                    trace!("child is hash {:?}", hash);
                }
                NodeHandle::InMemory(child_id) => {
                    self.print(child_id);
                }
            },
        };
    }
}

pub(crate) fn bitslice_to_bytes(bitslice: &BitSlice<u8, Msb0>) -> ByteVec {
    // TODO(perf): this should not copy to a bitvec :(
    iter::once(bitslice.len() as u8)
        .chain(bitslice.to_bitvec().as_raw_slice().iter().copied())
        .collect()
}

pub(crate) fn bytes_to_bitvec(bytes: &[u8]) -> BitVec<u8, Msb0> {
    BitSlice::from_slice(&bytes[1..]).to_bitvec()
}

#[cfg(test)]
#[cfg(all(test, feature = "std", feature = "rocksdb"))]
mod tests {
    use bitvec::{order::Msb0, vec::BitVec, view::BitView};
    use indexmap::IndexMap;
    use proptest::{arbitrary::arbitrary, strategy::Strategy};
    use starknet_types_core::{felt::Felt, hash::Pedersen};

    use crate::{
        databases::{create_rocks_db, RocksDB, RocksDBConfig},
        id::BasicId,
        BonsaiStorage, BonsaiStorageConfig, ByteVec,
    };

    #[test_log::test]
    // The whole point of this test is to make sure it is possible to reconstruct the original
    // keys from the data present in the db.
    fn test_key_retrieval() {
        let tempdir = tempfile::tempdir().unwrap();
        let rocksdb = create_rocks_db(tempdir.path()).unwrap();
        let db = RocksDB::new(&rocksdb, RocksDBConfig::default());
        let mut bonsai =
            BonsaiStorage::<BasicId, _, Pedersen>::new(db, BonsaiStorageConfig::default()).unwrap();

        let block_0 = vec![
            (
                str_to_felt_bytes(
                    "0x031c887d82502ceb218c06ebb46198da3f7b92864a8223746bc836dda3e34b52",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000065",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00cfc2e2866fd08bfb4ac73b70e0c136e326ae18fc797a2c090c8811c695577e",
                        ),
                        str_to_felt_bytes(
                            "0x05f1dd5a5aef88e0498eeca4e7b2ea0fa7110608c11531278742f0b5499af4b3",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05aee31408163292105d875070f98cb48275b8c87e80380b78d30647e05854d5",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05fac6815fddf6af1ca5e592359862ede14f171e1544fd9e792288164097c35d",
                        ),
                        str_to_felt_bytes(
                            "0x00299e2f4b5a873e95e65eb03d31e532ea2cde43b498b50cd3161145db5542a5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05fac6815fddf6af1ca5e592359862ede14f171e1544fd9e792288164097c35e",
                        ),
                        str_to_felt_bytes(
                            "0x03d6897cf23da3bf4fd35cc7a43ccaf7c5eaf8f7c5b9031ac9b09a929204175f",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x06ee3440b08a9c805305449ec7f7003f27e9f7e287b83610952ec36bdc5a6bae",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x01e2cd4b3588e8f6f9c4e89fb0e293bf92018c96d7a93ee367d29a284223b6ff",
                        ),
                        str_to_felt_bytes(
                            "0x071d1e9d188c784a0bde95c1d508877a0d93e9102b37213d1e13f3ebc54a7751",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0449908c349e90f81ab13042b1e49dc251eb6e3e51092d9a40f86859f7f415b0",
                        ),
                        str_to_felt_bytes(
                            "0x06cb6104279e754967a721b52bcf5be525fdc11fa6db6ef5c3a4db832acf7804",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x048cba68d4e86764105adcdcf641ab67b581a55a4f367203647549c8bf1feea2",
                        ),
                        str_to_felt_bytes(
                            "0x0362d24a3b030998ac75e838955dfee19ec5b6eceb235b9bfbeccf51b6304d0b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05bdaf1d47b176bfcd1114809af85a46b9c4376e87e361d86536f0288a284b65",
                        ),
                        str_to_felt_bytes(
                            "0x028dff6722aa73281b2cf84cac09950b71fa90512db294d2042119abdd9f4b87",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05bdaf1d47b176bfcd1114809af85a46b9c4376e87e361d86536f0288a284b66",
                        ),
                        str_to_felt_bytes(
                            "0x057a8f8a019ccab5bfc6ff86c96b1392257abb8d5d110c01d326b94247af161c",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05f750dc13ed239fa6fc43ff6e10ae9125a33bd05ec034fc3bb4dd168df3505f",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x0735596016a37ee972c42adef6a3cf628c19bb3794369c65d2c82ba034aecf2c",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000064",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x002f50710449a06a9fa789b3c029a63bd0b1f722f46505828a9f815cf91b31d8",
                        ),
                        str_to_felt_bytes(
                            "0x02a222e62eabe91abdb6838fa8b267ffe81a6eb575f61e96ec9aa4460c0925a2",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x020cfa74ee3564b4cd5435cdace0f9c4d43b939620e4a0bb5076105df0a626c6",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x000000000000000000000000000000000000000000000000000000000000022b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0313ad57fdf765addc71329abf8d74ac2bce6d46da8c2b9b82255a5076620300",
                        ),
                        str_to_felt_bytes(
                            "0x04e7e989d58a17cd279eca440c5eaa829efb6f9967aaad89022acbe644c39b36",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x0313ad57fdf765addc71329abf8d74ac2bce6d46da8c2b9b82255a5076620301",
                        ),
                        str_to_felt_bytes(
                            "0x0453ae0c9610197b18b13645c44d3d0a407083d96562e8752aab3fab616cecb0",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05aee31408163292105d875070f98cb48275b8c87e80380b78d30647e05854d5",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x06cf6c2f36d36b08e591e4489e92ca882bb67b9c39a3afccf011972a8de467f0",
                        ),
                        str_to_felt_bytes(
                            "0x07ab344d88124307c07b56f6c59c12f4543e9c96398727854a322dea82c73240",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x031c887d82502ceb218c06ebb46198da3f7b92864a8223746bc836dda3e34b52",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x00df28e613c065616a2e79ca72f9c1908e17b8c913972a9993da77588dc9cae9",
                        ),
                        str_to_felt_bytes(
                            "0x01432126ac23c7028200e443169c2286f99cdb5a7bf22e607bcd724efa059040",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05f750dc13ed239fa6fc43ff6e10ae9125a33bd05ec034fc3bb4dd168df3505f",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                ],
            ),
        ];

        let block_1 = vec![
            (
                str_to_felt_bytes(
                    "0x06538fdd3aa353af8a87f5fe77d1f533ea82815076e30a86d65b72d3eb4f0b80",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x000000000000000000000000000000000000000000000000000000000000022b",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x01aed933fd362faecd8ea54ee749092bd21f89901b7d1872312584ac5b636c6d",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007e5",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x010212fa2be788e5d943714d6a9eac5e07d8b4b48ead96b8d0a0cbe7a6dc3832",
                        ),
                        str_to_felt_bytes(
                            "0x008a81230a7e3ffa40abe541786a9b69fbb601434cec9536d5d5b2ee4df90383",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00ffda4b5cf0dce9bc9b0d035210590c73375fdbb70cd94ec6949378bffc410c",
                        ),
                        str_to_felt_bytes(
                            "0x02b36318931915f71777f7e59246ecab3189db48408952cefda72f4b7977be51",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x00ffda4b5cf0dce9bc9b0d035210590c73375fdbb70cd94ec6949378bffc410d",
                        ),
                        str_to_felt_bytes(
                            "0x07e928dcf189b05e4a3dae0bc2cb98e447f1843f7debbbf574151eb67cda8797",
                        ),
                    ),
                ],
            ),
            (
                str_to_felt_bytes(
                    "0x0327d34747122d7a40f4670265b098757270a449ec80c4871450fffdab7c2fa8",
                ),
                vec![
                    (
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000005",
                        ),
                        str_to_felt_bytes(
                            "0x0000000000000000000000000000000000000000000000000000000000000065",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x01aed933fd362faecd8ea54ee749092bd21f89901b7d1872312584ac5b636c6d",
                        ),
                        str_to_felt_bytes(
                            "0x00000000000000000000000000000000000000000000000000000000000007c7",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x04184fa5a6d40f47a127b046ed6facfa3e6bc3437b393da65cc74afe47ca6c6e",
                        ),
                        str_to_felt_bytes(
                            "0x001ef78e458502cd457745885204a4ae89f3880ec24db2d8ca97979dce15fedc",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05591c8c3c8d154a30869b463421cd5933770a0241e1a6e8ebcbd91bdd69bec4",
                        ),
                        str_to_felt_bytes(
                            "0x026b5943d4a0c420607cee8030a8cdd859bf2814a06633d165820960a42c6aed",
                        ),
                    ),
                    (
                        str_to_felt_bytes(
                            "0x05591c8c3c8d154a30869b463421cd5933770a0241e1a6e8ebcbd91bdd69bec5",
                        ),
                        str_to_felt_bytes(
                            "0x01518eec76afd5397cefd14eda48d01ad59981f9ce9e70c233ca67acd8754008",
                        ),
                    ),
                ],
            ),
        ];

        let block_2 = vec![
            (
                str_to_felt_bytes(
                    "0x001fb4457f3fe8a976bdb9c04dd21549beeeb87d3867b10effe0c4bd4064a8e4",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x056c060e7902b3d4ec5a327f1c6e083497e586937db00af37fe803025955678f",
                    ),
                    str_to_felt_bytes(
                        "0x075495b43f53bd4b9c9179db113626af7b335be5744d68c6552e3d36a16a747c",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x05790719f16afe1450b67a92461db7d0e36298d6a5f8bab4f7fd282050e02f4f",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x0772c29fae85f8321bb38c9c3f6edb0957379abedc75c17f32bcef4e9657911a",
                    ),
                    str_to_felt_bytes(
                        "0x06d4ca0f72b553f5338a95625782a939a49b98f82f449c20f49b42ec60ed891c",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x057b973bf2eb26ebb28af5d6184b4a044b24a8dcbf724feb95782c4d1aef1ca9",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x04f2c206f3f2f1380beeb9fe4302900701e1cb48b9b33cbe1a84a175d7ce8b50",
                    ),
                    str_to_felt_bytes(
                        "0x02a614ae71faa2bcdacc5fd66965429c57c4520e38ebc6344f7cf2e78b21bd2f",
                    ),
                )],
            ),
            (
                str_to_felt_bytes(
                    "0x02d6c9569dea5f18628f1ef7c15978ee3093d2d3eec3b893aac08004e678ead3",
                ),
                vec![(
                    str_to_felt_bytes(
                        "0x07f93985c1baa5bd9b2200dd2151821bd90abb87186d0be295d7d4b9bc8ca41f",
                    ),
                    str_to_felt_bytes(
                        "0x0127cd00a078199381403a33d315061123ce246c8e5f19aa7f66391a9d3bf7c6",
                    ),
                )],
            ),
        ];

        let blocks = block_0.iter().chain(block_1.iter()).chain(block_2.iter());

        // Inserts all storage updates into the bonsai
        for (contract_address, storage) in blocks.clone() {
            log::info!(
                "contract address (write): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );
            assert!(bonsai.init_tree(contract_address).is_ok());

            for (k, v) in storage {
                // truncate only keeps the first 251 bits in a key
                // so there should be no error during insertion
                let ktrunc = &truncate(k);
                let kfelt0 = Felt::from_bytes_be_slice(k);
                let kfelt1 = Felt::from_bytes_be_slice(ktrunc.as_raw_slice());

                // quick sanity check to make sure truncating a key does not remove any data
                assert_eq!(kfelt0, kfelt1);

                let v = &Felt::from_bytes_be_slice(v);
                assert!(bonsai.insert(contract_address, ktrunc, v).is_ok());
            }
        }
        assert!(bonsai.commit(BasicId::new(0)).is_ok());

        // aggreates all storage changes to their latest state
        // (replacements are takent into account)
        let mut storage_map = IndexMap::<ByteVec, IndexMap<Felt, Felt>>::new();
        for (contract_address, storage) in blocks.clone() {
            let map = storage_map
                .entry((*contract_address).into())
                .or_insert(IndexMap::new());

            for (k, v) in storage {
                let k = Felt::from_bytes_be_slice(k);
                let v = Felt::from_bytes_be_slice(v);
                map.insert(k, v);
            }
        }

        // checks for each contract if the original key can be reconstructed
        // from the data stored in the db
        for (contract_address, storage) in storage_map.iter() {
            log::info!(
                "contract address (read): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );

            let keys = bonsai.get_keys(contract_address).unwrap();
            log::debug!("{keys:?}");
            for k in keys {
                // if all has gone well, the db should contain the first 251 bits of the key,
                // which should represent the entirety of the data
                let k = Felt::from_bytes_be_slice(&k);
                log::info!("looking for key: {k:#064x}");

                assert!(storage.contains_key(&k));
            }
        }

        // makes sure retrieving key-value pairs works for each contract
        for (contract_address, storage) in storage_map.iter() {
            log::info!(
                "contract address (read): {:#064x}",
                Felt::from_bytes_be_slice(contract_address)
            );

            let kv = bonsai.get_key_value_pairs(contract_address).unwrap();
            log::debug!("{kv:?}");
            for (k, v) in kv {
                let k = Felt::from_bytes_be_slice(&k);
                let v = Felt::from_bytes_be_slice(&v);
                log::info!("checking for key-value pair:({k:#064x}, {v:#064x})");

                assert_eq!(*storage.get(&k).unwrap(), v);
            }
        }
    }

    fn str_to_felt_bytes(hex: &str) -> [u8; 32] {
        Felt::from_hex(hex).unwrap().to_bytes_be()
    }

    fn truncate(key: &[u8]) -> BitVec<u8, Msb0> {
        key.view_bits()[5..].to_owned()
    }

    mod proptests {
        use crate::databases::HashMapDb;
        use crate::key_value_db::KeyValueDB;
        use crate::trie::merkle_node::{Node, NodeHandle, NodeId};
        use crate::trie::merkle_tree::{MerkleTree, RootHandle};

        use super::*;
        use proptest::collection::vec;
        use proptest::prelude::*;
        use smallvec::smallvec;
        use starknet_types_core::hash::StarkHash;

        #[derive(Debug)]
        struct MerkleTreeMergeProblem {
            inserts_a: Vec<(BitVec<u8, Msb0>, Felt)>,
            inserts_b: Vec<(BitVec<u8, Msb0>, Felt)>,
        }

        impl Arbitrary for MerkleTreeMergeProblem {
            type Parameters = ();
            type Strategy = BoxedStrategy<Self>;

            fn arbitrary_with(_args: Self::Parameters) -> Self::Strategy {
                let bitvec251 = <[bool; 251]>::arbitrary()
                    .prop_map(|arr| arr.into_iter().collect::<BitVec<u8, Msb0>>());

                let felt = bitvec251
                    .clone()
                    .prop_map(|vec| Felt::from_bytes_be(vec.as_raw_slice().try_into().unwrap()));

                let inserts = vec((bitvec251, felt), 0..100);

                (inserts.clone(), inserts)
                    .prop_map(|(inserts_a, inserts_b)| MerkleTreeMergeProblem {
                        inserts_a,
                        inserts_b,
                    })
                    .boxed()
            }
        }

        impl MerkleTreeMergeProblem {
            fn assert_tries_equal<H: StarkHash>(a: &MerkleTree<H>, b: &MerkleTree<H>) {
                fn assert_tries_equal_handle<H: StarkHash>(
                    a_handle: &NodeHandle,
                    a: &MerkleTree<H>,
                    b_handle: &NodeHandle,
                    b: &MerkleTree<H>,
                ) {
                    match (a_handle, b_handle) {
                        (NodeHandle::Hash(a), NodeHandle::Hash(b)) => {
                            if a != b {
                                panic!("felt {:?}, {:?} do not match", a, b)
                            }
                        }
                        (NodeHandle::InMemory(a_id), NodeHandle::InMemory(b_id)) => {
                            assert_tries_equal_nodeid(*a_id, a, *b_id, b)
                        }
                        (a, b) => panic!("node handle {:?}, {:?} do not match", a, b),
                    }
                }

                fn assert_tries_equal_nodeid<H: StarkHash>(
                    a_id: NodeId,
                    a: &MerkleTree<H>,
                    b_id: NodeId,
                    b: &MerkleTree<H>,
                ) {
                    let a_node = a.storage_nodes.0.get(&a_id).unwrap();
                    let b_node = b.storage_nodes.0.get(&b_id).unwrap();

                    match (a_node, b_node) {
                        (Node::Binary(a_node), Node::Binary(b_node)) => {
                            if a_node.height != b_node.height {
                                panic!("height {:?}, {:?} do not match", a_node, b_node)
                            }
                            assert_tries_equal_handle(&a_node.left, a, &b_node.left, b);
                            assert_tries_equal_handle(&a_node.right, a, &b_node.right, b);
                        }
                        (Node::Edge(a_node), Node::Edge(b_node)) => {
                            if a_node.height != b_node.height {
                                panic!("height {:?}, {:?} do not match", a_node, b_node)
                            }
                            if a_node.path != b_node.path {
                                panic!("height {:?}, {:?} do not match", a_node, b_node)
                            }
                            assert_tries_equal_handle(&a_node.child, a, &b_node.child, b);

                        },
                        (a, b) => panic!("node {:?}, {:?} do not match", a, b),
                    }
                }

                match (&a.root_node, &b.root_node) {
                    (None, None) => {}
                    (Some(a_handle), Some(b_handle)) => match (a_handle, b_handle) {
                        (RootHandle::Empty, RootHandle::Empty) => {}
                        (RootHandle::Loaded(a_id), RootHandle::Loaded(b_id)) => {
                            assert_tries_equal_nodeid(*a_id, a, *b_id, b);
                        },
                        (a, b) => panic!("root handle {:?}, {:?} do not match", a, b),
                    },
                    (a, b) => panic!("root node {:?}, {:?} do not match", a, b),
                }
            }

            fn check(&self) {
                let hashmap_db = KeyValueDB::<_, BasicId>::new(
                    HashMapDb::<BasicId>::default(),
                    Default::default(),
                    None,
                );

                let mut tree_a = MerkleTree::<Pedersen>::new(smallvec![0, 1, 2]);
                for (k, v) in &self.inserts_a {
                    tree_a.set(&hashmap_db, &k, *v).unwrap();
                }

                let mut tree_b = MerkleTree::<Pedersen>::new(smallvec![0, 1, 2]);
                for (k, v) in &self.inserts_b {
                    tree_b.set(&hashmap_db, &k, *v).unwrap();
                }

                tree_a.merge(tree_b);

                let mut tree_total = MerkleTree::<Pedersen>::new(smallvec![0, 1, 2]);
                for (k, v) in self.inserts_a.iter().chain(&self.inserts_b) {
                    tree_total.set(&hashmap_db, &k, *v).unwrap();
                }

                Self::assert_tries_equal(&tree_a, &tree_total);
            }
        }

        proptest::proptest! {
            #[test]
            fn merge_trees(pb in any::<MerkleTreeMergeProblem>()) {
                pb.check();
            }
        }
    }

    // use crate::{
    //     databases::{create_rocks_db, RocksDB, RocksDBConfig},
    //     id::BasicId,
    //     key_value_db::KeyValueDBConfig,
    //     KeyValueDB,
    // };
    // use bitvec::vec::BitVec;
    // use mp_felt::Felt252Wrapper;
    // use mp_hashers::pedersen::PedersenHasher;
    // use parity_scale_codec::{Decode, Encode};
    // use rand::prelude::*;
    // use starknet_types_core::{felt::Felt, hash::Pedersen};

    // // convert a Madara felt to a standard Felt
    // fn felt_from_madara_felt(madara_felt: &Felt252Wrapper) -> Felt {
    //     let encoded = madara_felt.encode();
    //     Felt::decode(&mut &encoded[..]).unwrap()
    // }

    // // convert a standard Felt to a Madara felt
    // fn madara_felt_from_felt(felt: &Felt) -> Felt252Wrapper {
    //     let encoded = felt.encode();
    //     Felt252Wrapper::decode(&mut &encoded[..]).unwrap()
    // }

    // #[test]
    // fn one_commit_tree_compare() {
    //     let mut elements = vec![];
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut rng = rand::thread_rng();
    //     let tree_size = rng.gen_range(10..100);
    //     for _ in 0..tree_size {
    //         let mut element = String::from("0x");
    //         let element_size = rng.gen_range(10..32);
    //         for _ in 0..element_size {
    //             let random_byte: u8 = rng.gen();
    //             element.push_str(&format!("{:02x}", random_byte));
    //         }
    //         elements.push(Felt::from_hex(&element).unwrap());
    //     }
    //     let madara_elements = elements
    //         .iter()
    //         .map(madara_felt_from_felt)
    //         .collect::<Vec<_>>();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let root_hash = mp_commitments::calculate_class_commitment_tree_root_hash::<PedersenHasher>(
    //         &madara_elements,
    //     );
    //     elements
    //         .iter()
    //         .zip(madara_elements.iter())
    //         .for_each(|(element, madara_element)| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*madara_element);
    //             let key = &element.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });
    //     bonsai_tree.display();
    //     assert_eq!(
    //         bonsai_tree.commit().unwrap(),
    //         felt_from_madara_felt(&root_hash)
    //     );
    // }

    // #[test]
    // fn simple_commits() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt::from_hex("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 felt_from_madara_felt(&calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                     madara_felt_from_felt(class_hash),
    //                 ));
    //             madara_tree.set(
    //                 madara_felt_from_felt(class_hash),
    //                 madara_felt_from_felt(&final_hash),
    //             );
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(&BitVec::from_vec(key.to_vec()), final_hash)
    //                 .unwrap();
    //         });
    //     }
    //     let madara_root_hash = madara_tree.commit();
    //     let bonsai_root_hash = bonsai_tree.commit().unwrap();
    //     assert_eq!(bonsai_root_hash, felt_from_madara_felt(&madara_root_hash));
    // }

    // #[test]
    // fn simple_commits_and_delete() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt::from_hex("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt::from_hex("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash = calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                 madara_felt_from_felt(class_hash),
    //             );
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(&BitVec::from_vec(key.to_vec()), Felt::ZERO)
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    // }

    // #[test]
    // fn multiple_commits_tree_compare() {
    //     let mut rng = rand::thread_rng();
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let nb_commits = rng.gen_range(2..4);
    //     for _ in 0..nb_commits {
    //         let mut elements = vec![];
    //         let tree_size = rng.gen_range(10..100);
    //         for _ in 0..tree_size {
    //             let mut element = String::from("0x");
    //             let element_size = rng.gen_range(10..32);
    //             for _ in 0..element_size {
    //                 let random_byte: u8 = rng.gen();
    //                 element.push_str(&format!("{:02x}", random_byte));
    //             }
    //             elements.push(Felt::from_hex(&element).unwrap());
    //         }
    //         elements.iter().for_each(|class_hash| {
    //             let final_hash = calculate_class_commitment_leaf_hash::<PedersenHasher>(
    //                 madara_felt_from_felt(class_hash),
    //             );
    //             madara_tree.set(madara_felt_from_felt(class_hash), final_hash);
    //             let key = &class_hash.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     felt_from_madara_felt(&final_hash),
    //                 )
    //                 .unwrap();
    //         });

    //         let bonsai_root_hash = bonsai_tree.commit().unwrap();
    //         let madara_root_hash = madara_tree.commit();
    //         assert_eq!(bonsai_root_hash, felt_from_madara_felt(&madara_root_hash));
    //     }
    // }

    // #[test]    // fn multiple_commits_tree_compare_with_deletes() {
    //     let mut rng = rand::thread_rng();
    //     let mut madara_tree = StateCommitmentTree::<PedersenHasher>::default();
    //     let rocks_db = create_rocks_db(std::path::Path::new("test_db")).unwrap();
    //     let mut db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let mut bonsai_tree: super::MerkleTree<PedersenHasher, RocksDB> =
    //         super::MerkleTree::empty(&mut db);
    //     let nb_commits = rng.gen_range(2..5);
    //     let mut elements_to_delete = vec![];
    //     for _ in 0..nb_commits {
    //         let mut elements = vec![];
    //         let tree_size = rng.gen_range(10..100);
    //         for _ in 0..tree_size {
    //             let mut element = String::from("0x");
    //             let element_size = rng.gen_range(10..32);
    //             for _ in 0..element_size {
    //                 let random_byte: u8 = rng.gen();
    //                 element.push_str(&format!("{:02x}", random_byte));
    //             }
    //             if rng.gen_bool(0.1) {
    //                 elements_to_delete.push(Felt::from_hex_be(&element).unwrap());
    //                 elements.push(Felt::from_hex_be(&element).unwrap());
    //             } else {
    //                 elements.push(Felt::from_hex_be(&element).unwrap());
    //             }
    //         }
    //         elements.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             madara_tree.set(*class_hash, final_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             bonsai_tree.set(&BitVec::from_vec(key.to_vec()), final_hash);
    //         });

    //         let bonsai_root_hash = bonsai_tree.commit();
    //         let madara_root_hash = madara_tree.commit();
    //         assert_eq!(bonsai_root_hash, madara_root_hash);
    //     }
    //     elements_to_delete.iter().for_each(|class_hash| {
    //         madara_tree.set(*class_hash, Felt::ZERO);
    //         let key = &class_hash.0.to_bytes_be()[..31];
    //         bonsai_tree.set(&BitVec::from_vec(key.to_vec()), Felt::ZERO);
    //     });

    //     let bonsai_root_hash = bonsai_tree.commit();
    //     let madara_root_hash = madara_tree.commit();
    //     assert_eq!(bonsai_root_hash, madara_root_hash);
    // }

    // #[test]
    // fn test_proof() {
    //     let tempdir = tempfile::tempdir().unwrap();
    //     let rocks_db = create_rocks_db(std::path::Path::new(tempdir.path())).unwrap();
    //     let rocks_db = RocksDB::new(&rocks_db, RocksDBConfig::default());
    //     let db = KeyValueDB::new(rocks_db, KeyValueDBConfig::default(), None);
    //     let mut bonsai_tree: super::MerkleTree<Pedersen, RocksDB<BasicId>, BasicId> =
    //         super::MerkleTree::new(db).unwrap();
    //     let elements = [
    //         [Felt252Wrapper::from_hex_be("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             bonsai_tree
    //                 .set(
    //                     &BitVec::from_vec(key.to_vec()),
    //                     Felt::from_bytes_be(&final_hash.0.to_bytes_be()),
    //                 )
    //                 .unwrap();
    //         });
    //     }
    //     bonsai_tree.commit().unwrap();
    //     let bonsai_proof = bonsai_tree
    //         .get_proof(&BitVec::from_vec(
    //             elements[0][0].0.to_bytes_be()[..31].to_vec(),
    //         ))
    //         .unwrap();
    //     println!("bonsai_proof: {:?}", bonsai_proof);
    // }

    // test in madara
    //     #[test]
    // fn test_proof() {
    //     let mut tree = super::merkle_patricia_tree::merkle_tree::MerkleTree::<PedersenHasher>::empty();
    //     let elements = [
    //         [Felt252Wrapper::from_hex_be("0x665342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D0303c195fec3ce2568b62052e").unwrap()],
    //         [Felt252Wrapper::from_hex_be("0x66342762FDD54D033c195fec3ce2568b62052e").unwrap()],
    //     ];
    //     for elem in elements {
    //         elem.iter().for_each(|class_hash| {
    //             let final_hash =
    //                 calculate_class_commitment_leaf_hash::<PedersenHasher>(*class_hash);
    //             let key = &class_hash.0.to_bytes_be()[..31];
    //             tree
    //                 .set(&BitVec::from_vec(key.to_vec()), final_hash)
    //         });
    //     }
    //     tree.commit();
    //     let bonsai_proof = tree.get_proof(&BitVec::from_vec(
    //         elements[0][0].0.to_bytes_be()[..31].to_vec(),
    //     ));
    //     println!("bonsai_proof: {:?}", bonsai_proof);
    // }
}
